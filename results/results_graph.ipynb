{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "today = date.today()\n",
    "api = wandb.Api()\n",
    "\n",
    "# # Find all csv files in the current directory\n",
    "csv_files = glob.glob(\"/home/lev/projects/TopoBenchmarkX/big_csv/*.csv\")\n",
    "# # Collect all the names of the csv files without the extension\n",
    "csv_names = [csv_file[:-4] for csv_file in csv_files]\n",
    "project_name = \"TopoBenchmarkX_Graph\"  \n",
    "user = \"telyatnikov_sap\"\n",
    "\n",
    "if project_name not in csv_names:\n",
    "    runs = api.runs(f\"{user}/{project_name}\")\n",
    "\n",
    "    summary_list, config_list, name_list = [], [], []\n",
    "    for run in runs:\n",
    "        # .summary contains the output keys/values for metrics like accuracy.\n",
    "        #  We call ._json_dict to omit large files\n",
    "        summary_list.append(run.summary._json_dict)\n",
    "\n",
    "        # .config contains the hyperparameters.\n",
    "        #  We remove special values that start with _.\n",
    "        config_list.append(\n",
    "            {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "        )\n",
    "\n",
    "        # .name is the human-readable name of the run.\n",
    "        name_list.append(run.name)\n",
    "\n",
    "    runs_df = pd.DataFrame(\n",
    "        {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\n",
    "    )\n",
    "\n",
    "    runs_df.to_csv(f\"{user}_{project_name}.csv\")\n",
    "else:\n",
    "    runs_df = pd.read_csv(f\"{user}_{project_name}.csv\", index_col=0)\n",
    "\n",
    "    for row in runs_df.iloc:\n",
    "        row[\"summary\"] = ast.literal_eval(row[\"summary\"])\n",
    "        row[\"config\"] = ast.literal_eval(row[\"config\"])\n",
    "\n",
    "\n",
    "for row in runs_df.iloc:\n",
    "    row[\"summary\"].update(row[\"config\"])\n",
    "\n",
    "lst = [i[\"summary\"] for i in runs_df.iloc]\n",
    "df = pd.DataFrame.from_dict(lst)\n",
    "\n",
    "df_init = df.copy()\n",
    "\n",
    "# Get average epoch run time\n",
    "df[\"epoch_run_time\"] = df[\"_runtime\"] / df[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, column_to_normalize):\n",
    "    # Use json_normalize to flatten the nested dictionaries into separate columns\n",
    "    flattened_df = pd.json_normalize(df[column_to_normalize])\n",
    "    # Rename columns to include 'nested_column' prefix\n",
    "    flattened_df.columns = [\n",
    "        f\"{column_to_normalize}.{col}\" for col in flattened_df.columns\n",
    "    ]\n",
    "    # Concatenate the flattened DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, flattened_df], axis=1)\n",
    "    # Get new columns names\n",
    "    new_columns = flattened_df.columns\n",
    "    # Drop the original nested column if needed\n",
    "    result_df.drop(column_to_normalize, axis=1, inplace=True)\n",
    "    return result_df, new_columns\n",
    "\n",
    "\n",
    "# Config columns to normalize\n",
    "columns_to_normalize = [\"model\", \"dataset\", \"callbacks\", \"paths\"]\n",
    "\n",
    "# Keep track of config columns added\n",
    "config_columns = []\n",
    "for column in columns_to_normalize:\n",
    "    df, columns = normalize_column(df, column)\n",
    "    config_columns.extend(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workout us_demographic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every rows where df['dataset.parameters.data_name'] == 'US-county-demos' extend the 'dataset.parameters.data_name' with dataset.parameters.task_variable \n",
    "# and set it to 'US-county-demos' + '-' + dataset.parameters.task_variable\n",
    "df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.data_name'] = df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.data_name'] + '-' + df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.task_variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train/loss', 'train/recall', 'test/accuracy', 'val/precision', 'trainer/global_step']\n",
      "['_wandb', 'lr-Adam', '_runtime', 'val/loss', 'test/auroc']\n",
      "['train/accuracy', 'test/loss', 'val/auroc', 'val/accuracy', 'test/precision']\n",
      "['_step', 'epoch', '_timestamp', 'val/recall', 'test/recall']\n",
      "['train/auroc', 'train/precision', 'seed', 'tags', 'extras']\n",
      "['trainer', 'ckpt_path', 'task_name', 'model/params/total', 'model/params/trainable']\n",
      "['model/params/non_trainable', 'val/mse', 'val/mae', 'train/mae', 'train/mse']\n",
      "['test/mae', 'test/mse', 'epoch_run_time', 'model.compile', 'model._target_']\n",
      "['model.model_name', 'model.model_domain', 'model.loss.task', 'model.loss._target_', 'model.loss.loss_type']\n",
      "['model.readout._target_', 'model.readout.hidden_dim', 'model.readout.readout_name', 'model.readout.num_cell_dimensions', 'model.backbone.act']\n",
      "['model.backbone.dropout', 'model.backbone._target_', 'model.backbone.num_layers', 'model.backbone.in_channels', 'model.backbone.hidden_channels']\n",
      "['model.optimizer.lr', 'model.optimizer._target_', 'model.optimizer._partial_', 'model.optimizer.weight_decay', 'model.scheduler.gamma']\n",
      "['model.scheduler._target_', 'model.scheduler._partial_', 'model.scheduler.step_size', 'model.head_model._target_', 'model.head_model.task_level']\n",
      "['model.head_model.in_channels', 'model.head_model.out_channels', 'model.head_model.pooling_type', 'model.head_model.head_model_name', 'model.feature_encoder._target_']\n",
      "['model.feature_encoder.in_channels', 'model.feature_encoder.encoder_name', 'model.feature_encoder.out_channels', 'model.feature_encoder.proj_dropout', 'model.backbone_wrapper._target_']\n",
      "['model.backbone_wrapper._partial_', 'model.backbone_wrapper.out_channels', 'model.backbone_wrapper.wrapper_name', 'model.backbone_wrapper.num_cell_dimensions', 'model.backbone.v2']\n",
      "['model.backbone.heads', 'model.backbone.concat', 'dataset._target_', 'dataset.parameters.k', 'dataset.parameters.task']\n",
      "['dataset.parameters.data_dir', 'dataset.parameters.data_name', 'dataset.parameters.data_seed', 'dataset.parameters.data_type', 'dataset.parameters.loss_type']\n",
      "['dataset.parameters.batch_size', 'dataset.parameters.pin_memory', 'dataset.parameters.split_type', 'dataset.parameters.task_level', 'dataset.parameters.train_prop']\n",
      "['dataset.parameters.data_domain', 'dataset.parameters.num_classes', 'dataset.parameters.num_workers', 'dataset.parameters.force_reload', 'dataset.parameters.num_features']\n",
      "['dataset.parameters.data_split_dir', 'dataset.parameters.monitor_metric', 'dataset.parameters.max_x_1_degree', 'dataset.parameters.max_node_degree', 'dataset.transforms.data_manipulations._target_']\n",
      "['dataset.transforms.data_manipulations.transform_name', 'dataset.transforms.data_manipulations.transform_type', 'dataset.transforms.data_manipulations.selected_fields', 'dataset.transforms.one_hot_node_degree_features._target_', 'dataset.transforms.one_hot_node_degree_features.max_degrees']\n",
      "['dataset.transforms.one_hot_node_degree_features.degrees_fields', 'dataset.transforms.one_hot_node_degree_features.transform_name', 'dataset.transforms.one_hot_node_degree_features.transform_type', 'dataset.transforms.one_hot_node_degree_features.features_fields', 'dataset.transforms.data_manipulations.std']\n",
      "['dataset.transforms.data_manipulations.mean', 'dataset.transforms.data_manipulations.num_features', 'dataset.parameters.max_dim_if_lifted', 'dataset.parameters.preserve_edge_attr_if_lifted', 'dataset.parameters.year']\n",
      "['dataset.parameters.task_variable', 'callbacks.model_summary._target_', 'callbacks.model_summary.max_depth', 'callbacks.early_stopping.mode', 'callbacks.early_stopping.strict']\n",
      "['callbacks.early_stopping.monitor', 'callbacks.early_stopping.verbose', 'callbacks.early_stopping._target_', 'callbacks.early_stopping.patience', 'callbacks.early_stopping.min_delta']\n",
      "['callbacks.early_stopping.check_finite', 'callbacks.early_stopping.stopping_threshold', 'callbacks.early_stopping.divergence_threshold', 'callbacks.early_stopping.check_on_train_epoch_end', 'callbacks.model_checkpoint.mode']\n",
      "['callbacks.model_checkpoint.dirpath', 'callbacks.model_checkpoint.monitor', 'callbacks.model_checkpoint.verbose', 'callbacks.model_checkpoint._target_', 'callbacks.model_checkpoint.filename']\n",
      "['callbacks.model_checkpoint.save_last', 'callbacks.model_checkpoint.save_top_k', 'callbacks.model_checkpoint.every_n_epochs', 'callbacks.model_checkpoint.save_weights_only', 'callbacks.model_checkpoint.every_n_train_steps']\n",
      "['callbacks.model_checkpoint.train_time_interval', 'callbacks.model_checkpoint.auto_insert_metric_name', 'callbacks.model_checkpoint.save_on_train_epoch_end', 'callbacks.rich_progress_bar._target_', 'callbacks.learning_rate_monitor._target_']\n",
      "['callbacks.learning_rate_monitor.logging_interval', 'paths.log_dir', 'paths.data_dir', 'paths.root_dir', 'paths.work_dir']\n",
      "['paths.output_dir']\n"
     ]
    }
   ],
   "source": [
    "# Print all columns 10 per line\n",
    "for i in range(0, len(df.columns), 5):\n",
    "    print(list(df.columns[i:i + 5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See unique datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['minesweeper' 'questions' 'tolokers' 'amazon_ratings' 'roman_empire'\n",
      " 'IMDB-MULTI' 'IMDB-BINARY' 'REDDIT-BINARY' 'NCI109' 'NCI1' 'PROTEINS'\n",
      " 'MUTAG' 'ZINC' 'PubMed' 'citeseer' 'Cora'\n",
      " 'US-county-demos-UnemploymentRate' 'US-county-demos-BachelorRate'\n",
      " 'US-county-demos-DeathRate' 'US-county-demos-BirthRate'\n",
      " 'US-county-demos-MigraRate' 'US-county-demos-MedianIncome'\n",
      " 'US-county-demos-Election']\n",
      "Num unique datasets: 23\n"
     ]
    }
   ],
   "source": [
    "print(df['dataset.parameters.data_name'].unique())\n",
    "print(\"Num unique datasets:\", len(df['dataset.parameters.data_name'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See unique models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gcn' 'gin' 'gat']\n"
     ]
    }
   ],
   "source": [
    "print(df['model.model_name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve batch problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['minesweeper', 'questions', 'tolokers', 'amazon_ratings', 'roman_empire']\n",
    "models = ['gcn', 'gin']\n",
    "# For the following models and datasets I mistook the batch size, it should be 1, instead of 256 or 128\n",
    "# Keep the run where batch size is 128 and then change the batch size to 1\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        # Change the batch size to 1 when it is 128\n",
    "        df.loc[(df['model.model_name'] == model) & (df['dataset.parameters.data_name'] == dataset) & (df['dataset.parameters.batch_size'] == 128), 'dataset.parameters.batch_size'] = 1\n",
    "        # Drop runs where batch size is 256\n",
    "        df.drop(df[(df['model.model_name'] == model) & (df['dataset.parameters.data_name'] == dataset) & (df['dataset.parameters.batch_size'] == 256)].index, inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve issue with projection dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5  0.25 0.  ]\n"
     ]
    }
   ],
   "source": [
    "print(df['model.feature_encoder.proj_dropout'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep rows where model.feature_encoder.proj_dropout is [0.5  0.25]\n",
    "df = df[df['model.feature_encoder.proj_dropout'].isin([0.5, 0.25])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gcn\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: questions\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: tolokers\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: amazon_ratings\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: IMDB-MULTI\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128 256]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: IMDB-BINARY\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128 256]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: REDDIT-BINARY\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128 256]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI109\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128 256]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI1\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128 256]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128 256]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64 32]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 2]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0]\n",
      "Column: seed\n",
      "[150  23   5   3  42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n",
      "Model: gin\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: questions\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: tolokers\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: amazon_ratings\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: IMDB-MULTI\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: IMDB-BINARY\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: REDDIT-BINARY\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI109\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI1\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64 32]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 2]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0]\n",
      "Column: seed\n",
      "[150  23   5   3  42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n",
      "Model: gat\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: questions\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: tolokers\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: amazon_ratings\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: IMDB-MULTI\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: IMDB-BINARY\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: REDDIT-BINARY\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI109\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI1\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64 32]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 2]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0]\n",
      "Column: seed\n",
      "[150  23   5   3  42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.num_layers\n",
      "[4 3 2 1]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n"
     ]
    }
   ],
   "source": [
    "# Sweeped parameters: \n",
    "sweeped_columns = [\n",
    "    'model.optimizer.lr', \n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.backbone.num_layers',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'dataset.parameters.batch_size',\n",
    "    'dataset.parameters.data_seed',\n",
    "    'seed',\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# For each model and dataset go over all the sweeped parameters and print the unique values\n",
    "for model in df['model.model_name'].unique():\n",
    "    print(f\"Model: {model}\")\n",
    "    for dataset in df['dataset.parameters.data_name'].unique():\n",
    "        print(f\"Dataset: {dataset}\")\n",
    "        for column in sweeped_columns:\n",
    "            print(f\"Column: {column}\")\n",
    "            print(df.loc[(df['model.model_name'] == model) & (df['dataset.parameters.data_name'] == dataset), column].unique())\n",
    "        \n",
    "        print('---------------NEW DATASET------------------')\n",
    "    print('---------------NEW MODEL------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best results for each model and dataset\n",
    "# 1. Keep the columns that are necessary for the comparison\n",
    "sweeped_columns = [\n",
    "    'model.optimizer.lr', \n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.backbone.num_layers',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'dataset.parameters.batch_size',\n",
    "    # 'dataset.parameters.data_seed',\n",
    "    # 'seed',\n",
    "]\n",
    "run_columns = ['dataset.parameters.data_seed','seed']\n",
    "\n",
    "# Dataset and model columns\n",
    "dataset_model_columns = ['model.model_name', 'dataset.parameters.data_name']\n",
    "\n",
    "# Performance columns\n",
    "performance_columns = [\n",
    "    'val/loss', 'test/loss',\n",
    "    'val/mae', 'test/mae',\n",
    "    'val/mse', 'test/mse',\n",
    "    'val/accuracy', 'test/accuracy',\n",
    "    'val/auroc','test/auroc',\n",
    "    'val/recall', 'test/recall',\n",
    "    'val/precision', 'test/precision',\n",
    "    ]\n",
    "keep_columns = dataset_model_columns + sweeped_columns + performance_columns + run_columns\n",
    "df = df[keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_classification = [\n",
    "    'val/accuracy', 'test/accuracy',\n",
    "    'val/auroc','test/auroc',\n",
    "    'val/recall', 'test/recall',\n",
    "    'val/precision', 'test/precision',\n",
    "    ]\n",
    "performance_regression = [\n",
    "    'val/mae', 'test/mae',\n",
    "    'val/mse', 'test/mse',\n",
    "    ]\n",
    "# Define a dict of dicts for each dataset the corresponding optimization metrics\n",
    "optimization_metrics = {\n",
    "    'IMDB-MULTI': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'IMDB-BINARY': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'REDDIT-BINARY': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'NCI109': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'NCI1': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'PROTEINS': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'MUTAG': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'Cora': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'citeseer': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'PubMed': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "\n",
    "    'roman_empire': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'amazon_ratings': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    \n",
    "    'tolokers': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'questions': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'minesweeper': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "\n",
    "    'ZINC': {'optim_metric': 'val/mse', 'eval_metric': 'test/mae', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    \n",
    "    'US-county-demos-UnemploymentRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-BachelorRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-DeathRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-BirthRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-MigraRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-MedianIncome': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-Election': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "\n",
    "} \n",
    "\n",
    "len(optimization_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique datasets\n",
    "datasets = list(df['dataset.parameters.data_name'].unique())\n",
    "# Get unique models\n",
    "models = list(df['model.model_name'].unique())\n",
    "\n",
    "best_results = defaultdict(dict)\n",
    "best_results_all_metrics = defaultdict(dict)\n",
    "best_runs = defaultdict(dict)\n",
    "# Got over each dataset and model and find the best result\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        # Get the subset of the DataFrame for the current dataset and model\n",
    "        subset = df[\n",
    "            (df['dataset.parameters.data_name'] == dataset)\n",
    "            & (df['model.model_name'] == model)\n",
    "        ]\n",
    "\n",
    "        optim_metric = optimization_metrics[dataset]['optim_metric']\n",
    "        eval_metric = optimization_metrics[dataset]['eval_metric']\n",
    "        direction = optimization_metrics[dataset]['direction']\n",
    "        \n",
    "        # Keep metrics that matters for dataset\n",
    "        performance_columns = optimization_metrics[dataset]['performance_columns']\n",
    "        subset = subset[dataset_model_columns + sweeped_columns + performance_columns + run_columns]\n",
    "\n",
    "        aggregated = subset.groupby(sweeped_columns, dropna=False).agg(\n",
    "            {col: [\"mean\", \"std\"] for col in performance_columns},\n",
    "        )\n",
    "\n",
    "         # Go from MultiIndex to Index\n",
    "        aggregated = aggregated.reset_index()\n",
    "        aggregated = aggregated.sort_values(\n",
    "                by=(optim_metric, \"mean\"), ascending=(direction == 'min')\n",
    "            )\n",
    "        \n",
    "        # Git percent in case of classification\n",
    "        if 'test/accuracy' in performance_columns:\n",
    "            # Go over all the performance columns and multiply by 100\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] *= 100\n",
    "                aggregated[(col, \"std\")] *= 100\n",
    "            \n",
    "            # Round performance columns values up to 2 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(2)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(2)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # Round all values up to 4 decimal points\n",
    "            # Round performance columns values up to 4 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(4)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(4)\n",
    "        \n",
    "            \n",
    "        \n",
    "        # Get the best result\n",
    "        final_best = aggregated.head(1)\n",
    "        \n",
    "        best_results[dataset][model] = {\n",
    "            \"mean\": final_best[(eval_metric, \"mean\")].values[0],\n",
    "            \"std\": final_best[(eval_metric, \"std\")].values[0],\n",
    "        }\n",
    "\n",
    "        # Extract best runs: \n",
    "        best_params = {}\n",
    "        for col in sweeped_columns:\n",
    "            best_params[col] = final_best[(col, '')].item()\n",
    "        \n",
    "        # Start with the entire DataFrame\n",
    "        filtered_subset = subset.copy()\n",
    "\n",
    "        # Iterate over each key-value pair in the best parameters dictionary and filter the DataFrame\n",
    "        for param, value in best_params.items():\n",
    "            filtered_subset = filtered_subset[filtered_subset[param] == value]\n",
    "        best_runs[dataset][model] = filtered_subset\n",
    "        \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save obtained best results and best runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert nested dictionary to DataFrame\n",
    "nested_dict = dict(best_results)\n",
    "result_dict = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (i, j): nested_dict[i][j]\n",
    "        for i in nested_dict\n",
    "        for j in nested_dict[i].keys()\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "\n",
    "result_dict[\"performance\"] = result_dict.apply(\n",
    "    lambda x: f\"{x['mean']} ± {x['std']}\", axis=1\n",
    ")\n",
    "result_dict = result_dict.drop([\"mean\", \"std\"], axis=1)\n",
    "\n",
    "# Reset multiindex\n",
    "result_dict = result_dict.reset_index()\n",
    "# rename columns\n",
    "result_dict.columns = [\"Dataset\", \"Model\", \"Performance\"]\n",
    "\n",
    "result_dict = result_dict.pivot_table(\n",
    "    index=\"Model\", columns=\"Dataset\", values=\"Performance\", aggfunc=\"first\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the number of allowed rows to display\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "result_dict.to_csv(f\"best_results_graph.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

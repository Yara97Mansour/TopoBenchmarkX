{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "today = date.today()\n",
    "api = wandb.Api()\n",
    "\n",
    "# # Find all csv files in the current directory\n",
    "csv_files = glob.glob(\"/home/lev/projects/TopoBenchmarkX/big_csv/*.csv\")\n",
    "# # Collect all the names of the csv files without the extension\n",
    "csv_names = [csv_file[:-4] for csv_file in csv_files]\n",
    "project_name = \"TopoBenchmarkX_Simplicial\"  \n",
    "user = \"telyatnikov_sap\"\n",
    "\n",
    "if project_name not in csv_names:\n",
    "    runs = api.runs(f\"{user}/{project_name}\")\n",
    "\n",
    "    summary_list, config_list, name_list = [], [], []\n",
    "    for run in runs:\n",
    "        # .summary contains the output keys/values for metrics like accuracy.\n",
    "        #  We call ._json_dict to omit large files\n",
    "        summary_list.append(run.summary._json_dict)\n",
    "\n",
    "        # .config contains the hyperparameters.\n",
    "        #  We remove special values that start with _.\n",
    "        config_list.append(\n",
    "            {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "        )\n",
    "\n",
    "        # .name is the human-readable name of the run.\n",
    "        name_list.append(run.name)\n",
    "\n",
    "    runs_df = pd.DataFrame(\n",
    "        {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\n",
    "    )\n",
    "\n",
    "    runs_df.to_csv(f\"{user}_{project_name}.csv\")\n",
    "else:\n",
    "    runs_df = pd.read_csv(f\"{user}_{project_name}.csv\", index_col=0)\n",
    "\n",
    "    for row in runs_df.iloc:\n",
    "        row[\"summary\"] = ast.literal_eval(row[\"summary\"])\n",
    "        row[\"config\"] = ast.literal_eval(row[\"config\"])\n",
    "\n",
    "\n",
    "for row in runs_df.iloc:\n",
    "    row[\"summary\"].update(row[\"config\"])\n",
    "\n",
    "lst = [i[\"summary\"] for i in runs_df.iloc]\n",
    "df = pd.DataFrame.from_dict(lst)\n",
    "\n",
    "df_init = df.copy()\n",
    "\n",
    "# Get average epoch run time\n",
    "df[\"epoch_run_time\"] = df[\"_runtime\"] / df[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_init.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, column_to_normalize):\n",
    "    # Use json_normalize to flatten the nested dictionaries into separate columns\n",
    "    flattened_df = pd.json_normalize(df[column_to_normalize])\n",
    "    # Rename columns to include 'nested_column' prefix\n",
    "    flattened_df.columns = [\n",
    "        f\"{column_to_normalize}.{col}\" for col in flattened_df.columns\n",
    "    ]\n",
    "    # Concatenate the flattened DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, flattened_df], axis=1)\n",
    "    # Get new columns names\n",
    "    new_columns = flattened_df.columns\n",
    "    # Drop the original nested column if needed\n",
    "    result_df.drop(column_to_normalize, axis=1, inplace=True)\n",
    "    return result_df, new_columns\n",
    "\n",
    "\n",
    "# Config columns to normalize\n",
    "columns_to_normalize = [\"model\", \"dataset\", \"callbacks\", \"paths\"]\n",
    "\n",
    "# Keep track of config columns added\n",
    "config_columns = []\n",
    "for column in columns_to_normalize:\n",
    "    df, columns = normalize_column(df, column)\n",
    "    config_columns.extend(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate tables to obtain full hp space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "additiona_runs = pd.read_csv(f'gbg141_{project_name}.csv', index_col=0)\n",
    "df = pd.concat([df, additiona_runs], axis=0)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select models that have finished the runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workout us_demographic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every rows where df['dataset.parameters.data_name'] == 'US-county-demos' extend the 'dataset.parameters.data_name' with dataset.parameters.task_variable \n",
    "# and set it to 'US-county-demos' + '-' + dataset.parameters.task_variable\n",
    "df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.data_name'] = df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.data_name'] + '-' + df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.task_variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train/loss', 'val/precision', 'trainer/global_step', '_step', '_runtime']\n",
      "['val/auroc', 'train/accuracy', 'train/precision', 'epoch', 'val/recall']\n",
      "['train/auroc', 'train/recall', 'lr-Adam', '_timestamp', 'val/accuracy']\n",
      "['val/loss', 'seed', 'tags', 'extras', 'trainer']\n",
      "['ckpt_path', 'task_name', 'model/params/total', 'model/params/trainable', 'model/params/non_trainable']\n",
      "['test/auroc', 'test/accuracy', '_wandb', 'test/recall', 'test/precision']\n",
      "['test/loss', 'train/mse', 'val/mae', 'val/mse', 'test/mae']\n",
      "['test/mse', 'train/mae', 'model.compile', 'model._target_', 'model.model_name']\n",
      "['model.model_domain', 'model.loss.task', 'model.loss._target_', 'model.loss.loss_type', 'model.readout._target_']\n",
      "['model.readout.hidden_dim', 'model.readout.readout_name', 'model.readout.num_cell_dimensions', 'model.backbone._target_', 'model.backbone.n_layers']\n",
      "['model.backbone.in_channels_0', 'model.backbone.in_channels_1', 'model.backbone.in_channels_2', 'model.optimizer.lr', 'model.optimizer._target_']\n",
      "['model.optimizer._partial_', 'model.optimizer.weight_decay', 'model.scheduler._target_', 'model.scheduler._partial_', 'model.scheduler.last_epoch']\n",
      "['model.scheduler.total_iters', 'model.head_model._target_', 'model.head_model.task_level', 'model.head_model.in_channels', 'model.head_model.out_channels']\n",
      "['model.head_model.pooling_type', 'model.head_model.head_model_name', 'model.feature_encoder._target_', 'model.feature_encoder.in_channels', 'model.feature_encoder.encoder_name']\n",
      "['model.feature_encoder.out_channels', 'model.feature_encoder.proj_dropout', 'model.feature_encoder.selected_dimensions', 'model.backbone_wrapper._target_', 'model.backbone_wrapper._partial_']\n",
      "['model.backbone_wrapper.out_channels', 'model.backbone_wrapper.wrapper_name', 'model.backbone_wrapper.num_cell_dimensions', 'model.backbone.channels', 'model.backbone.max_rank']\n",
      "['model.backbone.update_func', 'model.backbone.sc_order', 'model.backbone.aggr_norm', 'model.backbone.conv_order', 'model.backbone.in_channels_all']\n",
      "['model.backbone.hidden_channels_all', 'dataset._target_', 'dataset.parameters.k', 'dataset.parameters.task', 'dataset.parameters.data_dir']\n",
      "['dataset.parameters.data_name', 'dataset.parameters.data_seed', 'dataset.parameters.data_type', 'dataset.parameters.loss_type', 'dataset.parameters.batch_size']\n",
      "['dataset.parameters.pin_memory', 'dataset.parameters.split_type', 'dataset.parameters.task_level', 'dataset.parameters.train_prop', 'dataset.parameters.data_domain']\n",
      "['dataset.parameters.num_classes', 'dataset.parameters.num_workers', 'dataset.parameters.num_features', 'dataset.parameters.data_split_dir', 'dataset.parameters.monitor_metric']\n",
      "['dataset.transforms.graph2simplicial_lifting.signed', 'dataset.transforms.graph2simplicial_lifting._target_', 'dataset.transforms.graph2simplicial_lifting.complex_dim', 'dataset.transforms.graph2simplicial_lifting.transform_name', 'dataset.transforms.graph2simplicial_lifting.transform_type']\n",
      "['dataset.transforms.graph2simplicial_lifting.feature_lifting', 'dataset.transforms.graph2simplicial_lifting.preserve_edge_attr', 'dataset.parameters.force_reload', 'dataset.parameters.max_node_degree', 'dataset.transforms.data_manipulations._target_']\n",
      "['dataset.transforms.data_manipulations.transform_name', 'dataset.transforms.data_manipulations.transform_type', 'dataset.transforms.data_manipulations.selected_fields', 'dataset.transforms.one_hot_node_degree_features._target_', 'dataset.transforms.one_hot_node_degree_features.max_degree']\n",
      "['dataset.transforms.one_hot_node_degree_features.degrees_fields', 'dataset.transforms.one_hot_node_degree_features.transform_name', 'dataset.transforms.one_hot_node_degree_features.transform_type', 'dataset.transforms.one_hot_node_degree_features.features_fields', 'dataset.parameters.year']\n",
      "['dataset.parameters.task_variable', 'dataset.parameters.max_dim_if_lifted', 'dataset.parameters.preserve_edge_attr_if_lifted', 'callbacks.model_summary._target_', 'callbacks.model_summary.max_depth']\n",
      "['callbacks.early_stopping.mode', 'callbacks.early_stopping.strict', 'callbacks.early_stopping.monitor', 'callbacks.early_stopping.verbose', 'callbacks.early_stopping._target_']\n",
      "['callbacks.early_stopping.patience', 'callbacks.early_stopping.min_delta', 'callbacks.early_stopping.check_finite', 'callbacks.early_stopping.stopping_threshold', 'callbacks.early_stopping.divergence_threshold']\n",
      "['callbacks.early_stopping.check_on_train_epoch_end', 'callbacks.model_checkpoint.mode', 'callbacks.model_checkpoint.dirpath', 'callbacks.model_checkpoint.monitor', 'callbacks.model_checkpoint.verbose']\n",
      "['callbacks.model_checkpoint._target_', 'callbacks.model_checkpoint.filename', 'callbacks.model_checkpoint.save_last', 'callbacks.model_checkpoint.save_top_k', 'callbacks.model_checkpoint.every_n_epochs']\n",
      "['callbacks.model_checkpoint.save_weights_only', 'callbacks.model_checkpoint.every_n_train_steps', 'callbacks.model_checkpoint.train_time_interval', 'callbacks.model_checkpoint.auto_insert_metric_name', 'callbacks.model_checkpoint.save_on_train_epoch_end']\n",
      "['callbacks.rich_progress_bar._target_', 'callbacks.learning_rate_monitor._target_', 'callbacks.learning_rate_monitor.logging_interval', 'paths.log_dir', 'paths.data_dir']\n",
      "['paths.root_dir', 'paths.work_dir', 'paths.output_dir', 'epoch_run_time', 'dataset.transforms.one_hot_node_degree_features.max_degrees']\n"
     ]
    }
   ],
   "source": [
    "# Print all columns 10 per line\n",
    "for i in range(0, len(df.columns), 5):\n",
    "    print(list(df.columns[i:i + 5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See unique datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NCI1' 'NCI109' 'minesweeper' 'roman_empire' 'ZINC' 'PROTEINS' 'PubMed'\n",
      " 'citeseer' 'Cora' 'US-county-demos-UnemploymentRate'\n",
      " 'US-county-demos-BachelorRate' 'MUTAG' 'US-county-demos-DeathRate'\n",
      " 'US-county-demos-BirthRate' 'US-county-demos-MigraRate'\n",
      " 'US-county-demos-MedianIncome' 'US-county-demos-Election']\n",
      "Num unique datasets: 17\n"
     ]
    }
   ],
   "source": [
    "print(df['dataset.parameters.data_name'].unique())\n",
    "print(\"Num unique datasets:\", len(df['dataset.parameters.data_name'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See unique models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scn' 'sccn' 'sccnn_custom']\n"
     ]
    }
   ],
   "source": [
    "print(df['model.model_name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve batch problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: sccnn_custom\n",
      "[1]\n",
      "[1]\n",
      "MODEL: scn\n",
      "[1]\n",
      "[1]\n",
      "MODEL: sccn\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "datasets = ['minesweeper', 'roman_empire']\n",
    "models = ['sccnn_custom', 'scn', 'sccn']\n",
    "# For the following models and datasets I mistook the batch size, it should be 1, instead of 256 or 128\n",
    "# Keep the run where batch size is 128 and then change the batch size to 1\n",
    "for model in models:\n",
    "    print(\"MODEL:\", model)\n",
    "    for dataset in datasets:\n",
    "\n",
    "        # Change the batch size to 1 when it is 128\n",
    "        \n",
    "        print(df.loc[(df['model.model_name'] == model) & (df['dataset.parameters.data_name'] == dataset), 'dataset.parameters.batch_size'].unique())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve issue with projection dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5  0.25]\n"
     ]
    }
   ],
   "source": [
    "print(df['model.feature_encoder.proj_dropout'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep rows where model.feature_encoder.proj_dropout is [0.5  0.25]\n",
    "df = df[df['model.feature_encoder.proj_dropout'].isin([0.5, 0.25])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: scn\n",
      "Dataset: NCI1\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[64 32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 3 4 1]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128 256]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0 9 5 3 7]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI109\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[64 32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 3 4 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[7 9 5 0 3]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[ 32 128  64]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[5 3 0 9 7]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[0.01]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64 32]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n",
      "Model: sccn\n",
      "Dataset: NCI1\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[ 32  64 128]\n",
      "Column: model.backbone.n_layers\n",
      "[1 4 3 2]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128 256]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0 5 7 9 3]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI109\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[ 32  64 128]\n",
      "Column: model.backbone.n_layers\n",
      "[1 4 3 2]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.25 0.5 ]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128 256]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 0 7 5 3]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[5 7 0 3 9]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[7 0 5 9 3]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 2]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128 256]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0]\n",
      "Column: seed\n",
      "[  5   3 150  42  23]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[7 3 0 9 5]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64 32]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 0 5 3]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n",
      "Model: sccnn_custom\n",
      "Dataset: NCI1\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[ 64  32 128]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0 3 7 9 5]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI109\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[ 64  32 128]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 3 0 5]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 2]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0]\n",
      "Column: seed\n",
      "[ 23   5  42   3 150]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64 32]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n"
     ]
    }
   ],
   "source": [
    "# Sweeped parameters: \n",
    "sweeped_columns = [\n",
    "    'model.optimizer.lr', \n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.readout.readout_name',\n",
    "    'dataset.transforms.graph2simplicial_lifting.signed',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'dataset.parameters.batch_size',\n",
    "    'dataset.parameters.data_seed',\n",
    "    'seed',\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# For each model and dataset go over all the sweeped parameters and print the unique values\n",
    "for model in df['model.model_name'].unique():\n",
    "    print(f\"Model: {model}\")\n",
    "    for dataset in df['dataset.parameters.data_name'].unique():\n",
    "        print(f\"Dataset: {dataset}\")\n",
    "        for column in sweeped_columns:\n",
    "            print(f\"Column: {column}\")\n",
    "            print(df.loc[(df['model.model_name'] == model) & (df['dataset.parameters.data_name'] == dataset), column].unique())\n",
    "        \n",
    "        print('---------------NEW DATASET------------------')\n",
    "    print('---------------NEW MODEL------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best results for each model and dataset\n",
    "# 1. Keep the columns that are necessary for the comparison\n",
    "sweeped_columns = [\n",
    "    'model.optimizer.lr', \n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.readout.readout_name',\n",
    "    'dataset.transforms.graph2simplicial_lifting.signed',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'dataset.parameters.batch_size',\n",
    "]\n",
    "run_columns = ['dataset.parameters.data_seed','seed']\n",
    "\n",
    "# Dataset and model columns\n",
    "dataset_model_columns = ['model.model_name', 'dataset.parameters.data_name']\n",
    "\n",
    "# Performance columns\n",
    "performance_columns = [\n",
    "    'val/loss', 'test/loss',\n",
    "    'val/mae', 'test/mae',\n",
    "    'val/mse', 'test/mse',\n",
    "    'val/accuracy', 'test/accuracy',\n",
    "    'val/auroc','test/auroc',\n",
    "    'val/recall', 'test/recall',\n",
    "    'val/precision', 'test/precision',\n",
    "    ]\n",
    "keep_columns = dataset_model_columns + sweeped_columns + performance_columns + run_columns\n",
    "df = df[keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_classification = [\n",
    "    'val/accuracy', 'test/accuracy',\n",
    "    'val/auroc','test/auroc',\n",
    "    'val/recall', 'test/recall',\n",
    "    'val/precision', 'test/precision',\n",
    "    ]\n",
    "performance_regression = [\n",
    "    'val/mae', 'test/mae',\n",
    "    'val/mse', 'test/mse',\n",
    "    ]\n",
    "# Define a dict of dicts for each dataset the corresponding optimization metrics\n",
    "optimization_metrics = {\n",
    "    'IMDB-MULTI': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'IMDB-BINARY': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'REDDIT-BINARY': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'NCI109': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'NCI1': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'PROTEINS': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'MUTAG': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'Cora': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'citeseer': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'PubMed': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "\n",
    "    'roman_empire': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'amazon_ratings': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    \n",
    "    'tolokers': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'questions': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'minesweeper': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "\n",
    "    'ZINC': {'optim_metric': 'val/mae', 'eval_metric': 'test/mae', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    \n",
    "    'US-county-demos-UnemploymentRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-BachelorRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-DeathRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-BirthRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-MigraRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-MedianIncome': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-Election': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "\n",
    "} \n",
    "\n",
    "len(optimization_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: NCI1, Model: scn\n",
      "Initial number of rows, 473\n",
      "Final number of rows , 466\n",
      "Rows that had NANs number of rows , -7\n",
      "Dataset: NCI1, Model: sccn\n",
      "Initial number of rows, 689\n",
      "Final number of rows , 679\n",
      "Rows that had NANs number of rows , -10\n",
      "Dataset: NCI1, Model: sccnn_custom\n",
      "Initial number of rows, 647\n",
      "Final number of rows , 646\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: NCI109, Model: scn\n",
      "Initial number of rows, 490\n",
      "Final number of rows , 485\n",
      "Rows that had NANs number of rows , -5\n",
      "Dataset: NCI109, Model: sccn\n",
      "Initial number of rows, 679\n",
      "Final number of rows , 669\n",
      "Rows that had NANs number of rows , -10\n",
      "Dataset: NCI109, Model: sccnn_custom\n",
      "Initial number of rows, 639\n",
      "Final number of rows , 638\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: minesweeper, Model: scn\n",
      "Initial number of rows, 636\n",
      "Final number of rows , 635\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: minesweeper, Model: sccn\n",
      "Initial number of rows, 479\n",
      "Final number of rows , 478\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: minesweeper, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: roman_empire, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: roman_empire, Model: sccn\n",
      "Initial number of rows, 469\n",
      "Final number of rows , 469\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: roman_empire, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: ZINC, Model: scn\n",
      "Initial number of rows, 0\n",
      "Final number of rows , 0\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: ZINC, Model: sccn\n",
      "Initial number of rows, 451\n",
      "Final number of rows , 439\n",
      "Rows that had NANs number of rows , -12\n",
      "Dataset: ZINC, Model: sccnn_custom\n",
      "Initial number of rows, 465\n",
      "Final number of rows , 465\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: scn\n",
      "Initial number of rows, 961\n",
      "Final number of rows , 961\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: sccn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: sccnn_custom\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: citeseer, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 239\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: citeseer, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: citeseer, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: Cora, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 239\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: Cora, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: Cora, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: scn\n",
      "Initial number of rows, 462\n",
      "Final number of rows , 461\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: sccn\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BachelorRate, Model: scn\n",
      "Initial number of rows, 462\n",
      "Final number of rows , 459\n",
      "Rows that had NANs number of rows , -3\n",
      "Dataset: US-county-demos-BachelorRate, Model: sccn\n",
      "Initial number of rows, 479\n",
      "Final number of rows , 479\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BachelorRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: MUTAG, Model: scn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: MUTAG, Model: sccn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 959\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: MUTAG, Model: sccnn_custom\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-DeathRate, Model: scn\n",
      "Initial number of rows, 448\n",
      "Final number of rows , 447\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: US-county-demos-DeathRate, Model: sccn\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-DeathRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BirthRate, Model: scn\n",
      "Initial number of rows, 450\n",
      "Final number of rows , 447\n",
      "Rows that had NANs number of rows , -3\n",
      "Dataset: US-county-demos-BirthRate, Model: sccn\n",
      "Initial number of rows, 456\n",
      "Final number of rows , 456\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BirthRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: scn\n",
      "Initial number of rows, 460\n",
      "Final number of rows , 460\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: sccn\n",
      "Initial number of rows, 450\n",
      "Final number of rows , 450\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: scn\n",
      "Initial number of rows, 462\n",
      "Final number of rows , 462\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: sccn\n",
      "Initial number of rows, 434\n",
      "Final number of rows , 434\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: scn\n",
      "Initial number of rows, 463\n",
      "Final number of rows , 463\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: sccn\n",
      "Initial number of rows, 454\n",
      "Final number of rows , 454\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n"
     ]
    }
   ],
   "source": [
    "# Get unique datasets\n",
    "datasets = list(df['dataset.parameters.data_name'].unique())\n",
    "# Get unique models\n",
    "models = list(df['model.model_name'].unique())\n",
    "\n",
    "best_results = defaultdict(dict)\n",
    "hp_runs = defaultdict(dict)\n",
    "best_runs = defaultdict(dict)\n",
    "# Got over each dataset and model and find the best result\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        # Get the subset of the DataFrame for the current dataset and model\n",
    "        subset = df[\n",
    "            (df['dataset.parameters.data_name'] == dataset)\n",
    "            & (df['model.model_name'] == model)\n",
    "        ]\n",
    "\n",
    "        optim_metric = optimization_metrics[dataset]['optim_metric']\n",
    "        eval_metric = optimization_metrics[dataset]['eval_metric']\n",
    "        direction = optimization_metrics[dataset]['direction']\n",
    "        \n",
    "        # Keep metrics that matters for dataset\n",
    "        performance_columns = optimization_metrics[dataset]['performance_columns']\n",
    "        subset = subset[dataset_model_columns + sweeped_columns + performance_columns + run_columns]\n",
    "\n",
    "        # --------WORKOUT NAN--------\n",
    "\n",
    "        print(f\"Dataset: {dataset}, Model: {model}\")\n",
    "        init_num_of_rows = subset.shape[0]\n",
    "        print(f'Initial number of rows, {init_num_of_rows}')\n",
    "\n",
    "        # Find 'NaN' in performance columns\n",
    "        # for each column find number of rows with 'NaN' string\n",
    "        total_performance_nan = 0\n",
    "        for column in performance_columns:\n",
    "            # Find the number of NaN string in the column\n",
    "            num_nan = subset[column].apply(lambda x: x == 'NaN')\n",
    "            num_nan = num_nan.sum()\n",
    "            total_performance_nan += num_nan        \n",
    "    \n",
    "        if total_performance_nan > 0:\n",
    "          \n",
    "            nan_rows = subset[performance_columns].eq('NaN')\n",
    "            nan_rows = nan_rows.sum(axis=1)\n",
    "            # Drop every rows where 'NaN' string is present\n",
    "            subset = subset[~nan_rows.gt(0)]\n",
    "           \n",
    "        # Ensure that the performance columns are of type float\n",
    "        subset[performance_columns] = subset[performance_columns].astype(float)\n",
    "    \n",
    "        for column in performance_columns:\n",
    "            if subset[column].isna().sum() > 0:  \n",
    "                subset = subset[~subset[column].isna()]\n",
    "\n",
    "        final_num_of_rows = subset.shape[0]  \n",
    "        print(f'Final number of rows , {final_num_of_rows}')\n",
    "        print(f'Rows that had NANs number of rows , {final_num_of_rows - init_num_of_rows}')\n",
    "\n",
    "        # --------WORKOUT NAN--------\n",
    "\n",
    "        aggregated = subset.groupby(sweeped_columns, dropna=False).agg(\n",
    "            {col: [\"mean\", \"std\"] for col in performance_columns}\n",
    "        )\n",
    "\n",
    "         # Go from MultiIndex to Index\n",
    "        aggregated = aggregated.reset_index()\n",
    "        aggregated = aggregated.sort_values(\n",
    "                by=(optim_metric, \"mean\"), ascending=(direction == 'min')\n",
    "            )\n",
    "        \n",
    "        # Git percent in case of classification\n",
    "        if 'test/accuracy' in performance_columns:\n",
    "            # Go over all the performance columns and multiply by 100\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] *= 100\n",
    "                aggregated[(col, \"std\")] *= 100\n",
    "            \n",
    "            # Round performance columns values up to 2 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(2)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(2)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # Round all values up to 4 decimal points\n",
    "            # Round performance columns values up to 4 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(4)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(4)\n",
    "        \n",
    "            \n",
    "        \n",
    "        # Get the best result\n",
    "        final_best = aggregated.head(1)\n",
    "        if final_best[(eval_metric, \"mean\")].any(): \n",
    "            best_results[dataset][model] = {\n",
    "                \"mean\": final_best[(eval_metric, \"mean\")].values[0],\n",
    "                \"std\": final_best[(eval_metric, \"std\")].values[0],\n",
    "            }\n",
    "\n",
    "            # Extract best runs: \n",
    "            best_params = {}\n",
    "            for col in sweeped_columns:\n",
    "                best_params[col] = final_best[(col, '')].item()\n",
    "            \n",
    "            hp_runs[dataset][model] = subset.copy()\n",
    "            \n",
    "            # Start with the entire DataFrame\n",
    "            filtered_subset = subset.copy()\n",
    "\n",
    "            # Iterate over each key-value pair in the best parameters dictionary and filter the DataFrame\n",
    "            for param, value in best_params.items():\n",
    "                filtered_subset = filtered_subset[filtered_subset[param] == value]\n",
    "            best_runs[dataset][model] = filtered_subset\n",
    "        \n",
    "        else: \n",
    "            best_results[dataset][model] = {\n",
    "                \"mean\": np.nan,\n",
    "                \"std\": np.nan,\n",
    "            }\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "COLS = [\n",
    "    'dataset.parameters.data_seed',\n",
    "    'dataset.parameters.batch_size',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.readout.readout_name',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'model.optimizer.lr', \n",
    "    \n",
    "]\n",
    "\n",
    "a = hp_runs['US-county-demos-BirthRate']['scn'].sort_values(by=COLS, ascending=False)[COLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in COLS:\n",
    "#     print(a[col].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save obtained best results and best runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert nested dictionary to DataFrame\n",
    "nested_dict = dict(best_results)\n",
    "result_dict = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (i, j): nested_dict[i][j]\n",
    "        for i in nested_dict\n",
    "        for j in nested_dict[i].keys()\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "\n",
    "result_dict[\"performance\"] = result_dict.apply(\n",
    "    lambda x: f\"{x['mean']} ± {x['std']}\", axis=1\n",
    ")\n",
    "result_dict = result_dict.drop([\"mean\", \"std\"], axis=1)\n",
    "\n",
    "# Reset multiindex\n",
    "result_dict = result_dict.reset_index()\n",
    "# rename columns\n",
    "result_dict.columns = [\"Dataset\", \"Model\", \"Performance\"]\n",
    "\n",
    "result_dict = result_dict.pivot_table(\n",
    "    index=\"Model\", columns=\"Dataset\", values=\"Performance\", aggfunc=\"first\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Cora</th>\n",
       "      <th>MUTAG</th>\n",
       "      <th>NCI1</th>\n",
       "      <th>NCI109</th>\n",
       "      <th>PROTEINS</th>\n",
       "      <th>PubMed</th>\n",
       "      <th>US-county-demos-BachelorRate</th>\n",
       "      <th>US-county-demos-BirthRate</th>\n",
       "      <th>US-county-demos-DeathRate</th>\n",
       "      <th>US-county-demos-Election</th>\n",
       "      <th>US-county-demos-MedianIncome</th>\n",
       "      <th>US-county-demos-MigraRate</th>\n",
       "      <th>US-county-demos-UnemploymentRate</th>\n",
       "      <th>ZINC</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>minesweeper</th>\n",
       "      <th>roman_empire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sccn</th>\n",
       "      <td>80.86 ± 2.16</td>\n",
       "      <td>70.64 ± 5.9</td>\n",
       "      <td>76.17 ± 1.39</td>\n",
       "      <td>75.49 ± 1.39</td>\n",
       "      <td>75.05 ± 2.76</td>\n",
       "      <td>88.37 ± 0.48</td>\n",
       "      <td>0.3588 ± 0.0246</td>\n",
       "      <td>0.8242 ± 0.0942</td>\n",
       "      <td>0.5751 ± 0.0553</td>\n",
       "      <td>0.5344 ± 0.0323</td>\n",
       "      <td>0.2908 ± 0.032</td>\n",
       "      <td>0.9146 ± 0.1822</td>\n",
       "      <td>0.4328 ± 0.044</td>\n",
       "      <td>0.4858 ± 0.0584</td>\n",
       "      <td>69.6 ± 1.83</td>\n",
       "      <td>89.07 ± 0.25</td>\n",
       "      <td>88.27 ± 0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sccnn_custom</th>\n",
       "      <td>82.19 ± 1.07</td>\n",
       "      <td>76.17 ± 6.63</td>\n",
       "      <td>76.6 ± 1.75</td>\n",
       "      <td>77.12 ± 1.07</td>\n",
       "      <td>74.19 ± 2.86</td>\n",
       "      <td>88.18 ± 0.32</td>\n",
       "      <td>0.3394 ± 0.028</td>\n",
       "      <td>0.7937 ± 0.1162</td>\n",
       "      <td>0.5527 ± 0.0474</td>\n",
       "      <td>0.5112 ± 0.0316</td>\n",
       "      <td>0.2825 ± 0.0279</td>\n",
       "      <td>0.8976 ± 0.1431</td>\n",
       "      <td>0.4278 ± 0.0394</td>\n",
       "      <td>0.4088 ± 0.0047</td>\n",
       "      <td>70.23 ± 2.69</td>\n",
       "      <td>89.0 ± 0.0</td>\n",
       "      <td>89.15 ± 0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scn</th>\n",
       "      <td>82.27 ± 1.34</td>\n",
       "      <td>73.62 ± 6.13</td>\n",
       "      <td>74.46 ± 1.11</td>\n",
       "      <td>75.7 ± 1.04</td>\n",
       "      <td>75.27 ± 2.14</td>\n",
       "      <td>88.72 ± 0.5</td>\n",
       "      <td>0.3186 ± 0.0241</td>\n",
       "      <td>0.7122 ± 0.0836</td>\n",
       "      <td>0.5208 ± 0.0525</td>\n",
       "      <td>0.4648 ± 0.043</td>\n",
       "      <td>0.2526 ± 0.0247</td>\n",
       "      <td>0.9209 ± 0.1993</td>\n",
       "      <td>0.3753 ± 0.0432</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>71.24 ± 1.68</td>\n",
       "      <td>90.32 ± 0.11</td>\n",
       "      <td>88.79 ± 0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset               Cora         MUTAG          NCI1        NCI109      PROTEINS        PubMed US-county-demos-BachelorRate US-county-demos-BirthRate US-county-demos-DeathRate US-county-demos-Election US-county-demos-MedianIncome US-county-demos-MigraRate US-county-demos-UnemploymentRate             ZINC      citeseer   minesweeper  roman_empire\n",
       "Model                                                                                                                                                                                                                                                                                                                                                        \n",
       "sccn          80.86 ± 2.16   70.64 ± 5.9  76.17 ± 1.39  75.49 ± 1.39  75.05 ± 2.76  88.37 ± 0.48              0.3588 ± 0.0246           0.8242 ± 0.0942           0.5751 ± 0.0553          0.5344 ± 0.0323               0.2908 ± 0.032           0.9146 ± 0.1822                   0.4328 ± 0.044  0.4858 ± 0.0584   69.6 ± 1.83  89.07 ± 0.25  88.27 ± 0.14\n",
       "sccnn_custom  82.19 ± 1.07  76.17 ± 6.63   76.6 ± 1.75  77.12 ± 1.07  74.19 ± 2.86  88.18 ± 0.32               0.3394 ± 0.028           0.7937 ± 0.1162           0.5527 ± 0.0474          0.5112 ± 0.0316              0.2825 ± 0.0279           0.8976 ± 0.1431                  0.4278 ± 0.0394  0.4088 ± 0.0047  70.23 ± 2.69    89.0 ± 0.0  89.15 ± 0.32\n",
       "scn           82.27 ± 1.34  73.62 ± 6.13  74.46 ± 1.11   75.7 ± 1.04  75.27 ± 2.14   88.72 ± 0.5              0.3186 ± 0.0241           0.7122 ± 0.0836           0.5208 ± 0.0525           0.4648 ± 0.043              0.2526 ± 0.0247           0.9209 ± 0.1993                  0.3753 ± 0.0432        nan ± nan  71.24 ± 1.68  90.32 ± 0.11  88.79 ± 0.46"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the number of allowed rows to display\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "result_dict.to_csv(f\"best_results_simplicial.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagate signal down comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: NCI1, Model: scn\n",
      "Initial number of rows, 473\n",
      "Final number of rows , 466\n",
      "Rows that had NANs number of rows , -7\n",
      "Dataset: NCI1, Model: sccn\n",
      "Initial number of rows, 689\n",
      "Final number of rows , 679\n",
      "Rows that had NANs number of rows , -10\n",
      "Dataset: NCI1, Model: sccnn_custom\n",
      "Initial number of rows, 647\n",
      "Final number of rows , 646\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: NCI109, Model: scn\n",
      "Initial number of rows, 490\n",
      "Final number of rows , 485\n",
      "Rows that had NANs number of rows , -5\n",
      "Dataset: NCI109, Model: sccn\n",
      "Initial number of rows, 679\n",
      "Final number of rows , 669\n",
      "Rows that had NANs number of rows , -10\n",
      "Dataset: NCI109, Model: sccnn_custom\n",
      "Initial number of rows, 639\n",
      "Final number of rows , 638\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: minesweeper, Model: scn\n",
      "Initial number of rows, 636\n",
      "Final number of rows , 635\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: minesweeper, Model: sccn\n",
      "Initial number of rows, 479\n",
      "Final number of rows , 478\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: minesweeper, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: roman_empire, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: roman_empire, Model: sccn\n",
      "Initial number of rows, 469\n",
      "Final number of rows , 469\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: roman_empire, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: ZINC, Model: scn\n",
      "Initial number of rows, 0\n",
      "Final number of rows , 0\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: ZINC, Model: sccn\n",
      "Initial number of rows, 451\n",
      "Final number of rows , 439\n",
      "Rows that had NANs number of rows , -12\n",
      "Dataset: ZINC, Model: sccnn_custom\n",
      "Initial number of rows, 465\n",
      "Final number of rows , 465\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: scn\n",
      "Initial number of rows, 961\n",
      "Final number of rows , 961\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: sccn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: sccnn_custom\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: citeseer, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 239\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: citeseer, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: citeseer, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: Cora, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 239\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: Cora, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: Cora, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: scn\n",
      "Initial number of rows, 462\n",
      "Final number of rows , 461\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: sccn\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BachelorRate, Model: scn\n",
      "Initial number of rows, 462\n",
      "Final number of rows , 459\n",
      "Rows that had NANs number of rows , -3\n",
      "Dataset: US-county-demos-BachelorRate, Model: sccn\n",
      "Initial number of rows, 479\n",
      "Final number of rows , 479\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BachelorRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: MUTAG, Model: scn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: MUTAG, Model: sccn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 959\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: MUTAG, Model: sccnn_custom\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-DeathRate, Model: scn\n",
      "Initial number of rows, 448\n",
      "Final number of rows , 447\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: US-county-demos-DeathRate, Model: sccn\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-DeathRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BirthRate, Model: scn\n",
      "Initial number of rows, 450\n",
      "Final number of rows , 447\n",
      "Rows that had NANs number of rows , -3\n",
      "Dataset: US-county-demos-BirthRate, Model: sccn\n",
      "Initial number of rows, 456\n",
      "Final number of rows , 456\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BirthRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: scn\n",
      "Initial number of rows, 460\n",
      "Final number of rows , 460\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: sccn\n",
      "Initial number of rows, 450\n",
      "Final number of rows , 450\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: scn\n",
      "Initial number of rows, 462\n",
      "Final number of rows , 462\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: sccn\n",
      "Initial number of rows, 434\n",
      "Final number of rows , 434\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: scn\n",
      "Initial number of rows, 463\n",
      "Final number of rows , 463\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: sccn\n",
      "Initial number of rows, 454\n",
      "Final number of rows , 454\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n"
     ]
    }
   ],
   "source": [
    "# Get unique datasets\n",
    "datasets = list(df['dataset.parameters.data_name'].unique())\n",
    "# Get unique models\n",
    "models = list(df['model.model_name'].unique())\n",
    "\n",
    "best_results = defaultdict(dict)\n",
    "hp_runs = defaultdict(dict)\n",
    "best_runs = defaultdict(dict)\n",
    "# Got over each dataset and model and find the best result\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        # Get the subset of the DataFrame for the current dataset and model\n",
    "        subset = df[\n",
    "            (df['dataset.parameters.data_name'] == dataset)\n",
    "            & (df['model.model_name'] == model)\n",
    "        ]\n",
    "\n",
    "        optim_metric = optimization_metrics[dataset]['optim_metric']\n",
    "        eval_metric = optimization_metrics[dataset]['eval_metric']\n",
    "        direction = optimization_metrics[dataset]['direction']\n",
    "        \n",
    "        # Keep metrics that matters for dataset\n",
    "        performance_columns = optimization_metrics[dataset]['performance_columns']\n",
    "        subset = subset[dataset_model_columns + sweeped_columns + performance_columns + run_columns]\n",
    "\n",
    "        # --------WORKOUT NAN--------\n",
    "\n",
    "        print(f\"Dataset: {dataset}, Model: {model}\")\n",
    "        init_num_of_rows = subset.shape[0]\n",
    "        print(f'Initial number of rows, {init_num_of_rows}')\n",
    "\n",
    "        # Find 'NaN' in performance columns\n",
    "        # for each column find number of rows with 'NaN' string\n",
    "        total_performance_nan = 0\n",
    "        for column in performance_columns:\n",
    "            # Find the number of NaN string in the column\n",
    "            num_nan = subset[column].apply(lambda x: x == 'NaN')\n",
    "            num_nan = num_nan.sum()\n",
    "            total_performance_nan += num_nan        \n",
    "    \n",
    "        if total_performance_nan > 0:\n",
    "          \n",
    "            nan_rows = subset[performance_columns].eq('NaN')\n",
    "            nan_rows = nan_rows.sum(axis=1)\n",
    "            # Drop every rows where 'NaN' string is present\n",
    "            subset = subset[~nan_rows.gt(0)]\n",
    "           \n",
    "        # Ensure that the performance columns are of type float\n",
    "        subset[performance_columns] = subset[performance_columns].astype(float)\n",
    "    \n",
    "        for column in performance_columns:\n",
    "            if subset[column].isna().sum() > 0:  \n",
    "                subset = subset[~subset[column].isna()]\n",
    "\n",
    "        final_num_of_rows = subset.shape[0]  \n",
    "        print(f'Final number of rows , {final_num_of_rows}')\n",
    "        print(f'Rows that had NANs number of rows , {final_num_of_rows - init_num_of_rows}')\n",
    "\n",
    "        # --------WORKOUT NAN--------\n",
    "\n",
    "\n",
    "        aggregated = subset.groupby(sweeped_columns, dropna=False).agg(\n",
    "            {col: [\"mean\", \"std\"] for col in performance_columns}\n",
    "        )\n",
    "\n",
    "         # Go from MultiIndex to Index\n",
    "        aggregated = aggregated.reset_index()\n",
    "        aggregated = aggregated.sort_values(\n",
    "                by=(optim_metric, \"mean\"), ascending=(direction == 'min')\n",
    "            )\n",
    "        \n",
    "        # Git percent in case of classification\n",
    "        if 'test/accuracy' in performance_columns:\n",
    "            # Go over all the performance columns and multiply by 100\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] *= 100\n",
    "                aggregated[(col, \"std\")] *= 100\n",
    "            \n",
    "            # Round performance columns values up to 2 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(2)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(2)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # Round all values up to 4 decimal points\n",
    "            # Round performance columns values up to 4 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(4)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(4)\n",
    "        \n",
    "        if sorted(list(aggregated['model.readout.readout_name'].unique())) == sorted(['NoReadOut', 'PropagateSignalDown']):\n",
    "            prop_types = ['NoReadOut', 'PropagateSignalDown']\n",
    "            for prop_type in prop_types:\n",
    "                agg_sub = aggregated[aggregated['model.readout.readout_name'] == prop_type]\n",
    "                agg_sub = agg_sub.sort_values(\n",
    "                    by=(optim_metric, \"mean\"), ascending=(direction == 'min')\n",
    "                )\n",
    "                \n",
    "                final_best = agg_sub.head(1)\n",
    "                if final_best[(eval_metric, \"mean\")].any(): \n",
    "                    best_results[dataset][f\"{model} ({prop_type})\"] = {\n",
    "                        \"mean\": final_best[(eval_metric, \"mean\")].values[0],\n",
    "                        \"std\": final_best[(eval_metric, \"std\")].values[0],\n",
    "                    }\n",
    "\n",
    "                    # Extract best runs: \n",
    "                    best_params = {}\n",
    "                    for col in sweeped_columns:\n",
    "                        best_params[col] = final_best[(col, '')].item()\n",
    "                    \n",
    "                    hp_runs[dataset][model] = subset.copy()\n",
    "                    \n",
    "                    # Start with the entire DataFrame\n",
    "                    filtered_subset = subset.copy()\n",
    "\n",
    "                    # Iterate over each key-value pair in the best parameters dictionary and filter the DataFrame\n",
    "                    for param, value in best_params.items():\n",
    "                        filtered_subset = filtered_subset[filtered_subset[param] == value]\n",
    "                    best_runs[dataset][model] = filtered_subset\n",
    "                \n",
    "                else: \n",
    "                    best_results[dataset][model] = {\n",
    "                        \"mean\": np.nan,\n",
    "                        \"std\": np.nan,\n",
    "                        \"prop_type\": prop_type\n",
    "                    }\n",
    "        else:\n",
    "            prop_types = ['NoReadOut', 'PropagateSignalDown']\n",
    "            for prop_type in prop_types:\n",
    "                best_results[dataset][f\"{model} ({prop_type})\"] = {\n",
    "                            \"mean\": np.nan,\n",
    "                            \"std\": np.nan,\n",
    "                        }\n",
    "\n",
    "       \n",
    "\n",
    "# Convert nested dictionary to DataFrame\n",
    "nested_dict = dict(best_results)\n",
    "result_dict = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (i, j): nested_dict[i][j]\n",
    "        for i in nested_dict\n",
    "        for j in nested_dict[i].keys()\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "\n",
    "result_dict[\"performance\"] = result_dict.apply(\n",
    "    lambda x: f\"{x['mean']} ± {x['std']}\", axis=1\n",
    ")\n",
    "result_dict = result_dict.drop([\"mean\", \"std\"], axis=1)\n",
    "\n",
    "# Reset multiindex\n",
    "result_dict = result_dict.reset_index()\n",
    "# rename columns\n",
    "result_dict.columns = [\"Dataset\", \"Model\", \"Performance\"]\n",
    "\n",
    "result_dict = result_dict.pivot_table(\n",
    "    index=\"Model\", columns=\"Dataset\", values=\"Performance\", aggfunc=\"first\"\n",
    ")\n",
    "result_dict.reset_index(inplace=True)\n",
    "\n",
    "result_dict['ReadOut'] = result_dict['Model'].apply(lambda x: x.split('(')[1].replace(')', ''))\n",
    "result_dict['Model'] = result_dict['Model'].apply(lambda x: x.split('(')[0])\n",
    "\n",
    "result_dict.sort_values(by=['Model','ReadOut'], inplace=True)\n",
    "\n",
    "columns = ['Model',\n",
    "'ReadOut',\n",
    " 'Cora',\n",
    " 'MUTAG',\n",
    " 'NCI1',\n",
    " 'NCI109',\n",
    " 'PROTEINS',\n",
    " 'PubMed',\n",
    " 'US-county-demos-BachelorRate',\n",
    " 'US-county-demos-BirthRate',\n",
    " 'US-county-demos-DeathRate',\n",
    " 'US-county-demos-Election',\n",
    " 'US-county-demos-MedianIncome',\n",
    " 'US-county-demos-MigraRate',\n",
    " 'US-county-demos-UnemploymentRate',\n",
    " 'ZINC',\n",
    " 'citeseer',\n",
    " 'minesweeper',\n",
    " 'roman_empire',]\n",
    "result_dict = result_dict[columns]\n",
    "result_dict.to_csv(f\"ablation_simplicial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>ReadOut</th>\n",
       "      <th>Cora</th>\n",
       "      <th>MUTAG</th>\n",
       "      <th>NCI1</th>\n",
       "      <th>NCI109</th>\n",
       "      <th>PROTEINS</th>\n",
       "      <th>PubMed</th>\n",
       "      <th>US-county-demos-BachelorRate</th>\n",
       "      <th>US-county-demos-BirthRate</th>\n",
       "      <th>US-county-demos-DeathRate</th>\n",
       "      <th>US-county-demos-Election</th>\n",
       "      <th>US-county-demos-MedianIncome</th>\n",
       "      <th>US-county-demos-MigraRate</th>\n",
       "      <th>US-county-demos-UnemploymentRate</th>\n",
       "      <th>ZINC</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>minesweeper</th>\n",
       "      <th>roman_empire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sccn</td>\n",
       "      <td>NoReadOut</td>\n",
       "      <td>80.86 ± 2.16</td>\n",
       "      <td>70.64 ± 5.9</td>\n",
       "      <td>76.42 ± 0.88</td>\n",
       "      <td>75.49 ± 1.39</td>\n",
       "      <td>75.05 ± 2.76</td>\n",
       "      <td>88.04 ± 0.51</td>\n",
       "      <td>0.3588 ± 0.0246</td>\n",
       "      <td>0.8242 ± 0.0942</td>\n",
       "      <td>0.5751 ± 0.0553</td>\n",
       "      <td>0.5344 ± 0.0323</td>\n",
       "      <td>0.2868 ± 0.0276</td>\n",
       "      <td>0.9146 ± 0.1822</td>\n",
       "      <td>0.4328 ± 0.044</td>\n",
       "      <td>0.5441 ± 0.0081</td>\n",
       "      <td>69.6 ± 1.83</td>\n",
       "      <td>88.85 ± 0.0</td>\n",
       "      <td>88.2 ± 0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sccn</td>\n",
       "      <td>PropagateSignalDown</td>\n",
       "      <td>80.06 ± 1.66</td>\n",
       "      <td>73.62 ± 4.41</td>\n",
       "      <td>76.17 ± 1.39</td>\n",
       "      <td>75.31 ± 1.36</td>\n",
       "      <td>74.34 ± 3.17</td>\n",
       "      <td>88.37 ± 0.48</td>\n",
       "      <td>0.341 ± 0.0249</td>\n",
       "      <td>0.8264 ± 0.1018</td>\n",
       "      <td>0.5629 ± 0.0444</td>\n",
       "      <td>0.5686 ± 0.0247</td>\n",
       "      <td>0.2908 ± 0.032</td>\n",
       "      <td>0.9303 ± 0.172</td>\n",
       "      <td>0.4734 ± 0.0377</td>\n",
       "      <td>0.4858 ± 0.0584</td>\n",
       "      <td>68.86 ± 2.4</td>\n",
       "      <td>89.07 ± 0.25</td>\n",
       "      <td>88.27 ± 0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sccnn_custom</td>\n",
       "      <td>NoReadOut</td>\n",
       "      <td>82.19 ± 1.07</td>\n",
       "      <td>76.17 ± 6.63</td>\n",
       "      <td>76.6 ± 1.75</td>\n",
       "      <td>77.12 ± 1.07</td>\n",
       "      <td>74.19 ± 2.86</td>\n",
       "      <td>88.18 ± 0.32</td>\n",
       "      <td>0.3394 ± 0.028</td>\n",
       "      <td>0.7937 ± 0.1162</td>\n",
       "      <td>0.5527 ± 0.0474</td>\n",
       "      <td>0.5112 ± 0.0316</td>\n",
       "      <td>0.2825 ± 0.0279</td>\n",
       "      <td>0.8976 ± 0.1431</td>\n",
       "      <td>0.4278 ± 0.0394</td>\n",
       "      <td>0.3562 ± 0.013</td>\n",
       "      <td>70.23 ± 2.69</td>\n",
       "      <td>87.4 ± 0.0</td>\n",
       "      <td>89.15 ± 0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sccnn_custom</td>\n",
       "      <td>PropagateSignalDown</td>\n",
       "      <td>80.65 ± 2.39</td>\n",
       "      <td>70.64 ± 3.16</td>\n",
       "      <td>75.6 ± 2.45</td>\n",
       "      <td>75.43 ± 1.94</td>\n",
       "      <td>74.98 ± 1.92</td>\n",
       "      <td>87.78 ± 0.58</td>\n",
       "      <td>0.3449 ± 0.0314</td>\n",
       "      <td>0.8251 ± 0.1184</td>\n",
       "      <td>0.579 ± 0.0541</td>\n",
       "      <td>0.557 ± 0.041</td>\n",
       "      <td>0.3073 ± 0.0316</td>\n",
       "      <td>0.9274 ± 0.1711</td>\n",
       "      <td>0.4538 ± 0.0428</td>\n",
       "      <td>0.4088 ± 0.0047</td>\n",
       "      <td>69.03 ± 2.01</td>\n",
       "      <td>89.0 ± 0.0</td>\n",
       "      <td>88.73 ± 0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scn</td>\n",
       "      <td>NoReadOut</td>\n",
       "      <td>82.27 ± 1.34</td>\n",
       "      <td>71.49 ± 2.43</td>\n",
       "      <td>75.27 ± 1.57</td>\n",
       "      <td>75.7 ± nan</td>\n",
       "      <td>75.27 ± 2.14</td>\n",
       "      <td>88.72 ± 0.5</td>\n",
       "      <td>0.3186 ± 0.0241</td>\n",
       "      <td>0.7122 ± 0.0836</td>\n",
       "      <td>0.5208 ± 0.0525</td>\n",
       "      <td>0.4648 ± 0.043</td>\n",
       "      <td>0.2526 ± 0.0247</td>\n",
       "      <td>0.9209 ± 0.1993</td>\n",
       "      <td>0.3753 ± 0.0432</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>71.24 ± 1.68</td>\n",
       "      <td>90.32 ± 0.11</td>\n",
       "      <td>85.89 ± 0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scn</td>\n",
       "      <td>PropagateSignalDown</td>\n",
       "      <td>79.91 ± 1.18</td>\n",
       "      <td>73.62 ± 6.13</td>\n",
       "      <td>74.46 ± 1.11</td>\n",
       "      <td>75.7 ± 1.04</td>\n",
       "      <td>74.77 ± 1.69</td>\n",
       "      <td>88.62 ± 0.44</td>\n",
       "      <td>0.3205 ± 0.0271</td>\n",
       "      <td>0.7985 ± 0.1062</td>\n",
       "      <td>0.5635 ± 0.0457</td>\n",
       "      <td>0.5091 ± 0.0345</td>\n",
       "      <td>0.2723 ± 0.0174</td>\n",
       "      <td>0.9619 ± 0.2329</td>\n",
       "      <td>0.4131 ± 0.0297</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>70.4 ± 1.53</td>\n",
       "      <td>90.27 ± 0.36</td>\n",
       "      <td>88.79 ± 0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset          Model              ReadOut          Cora         MUTAG          NCI1        NCI109      PROTEINS        PubMed US-county-demos-BachelorRate US-county-demos-BirthRate US-county-demos-DeathRate US-county-demos-Election US-county-demos-MedianIncome US-county-demos-MigraRate US-county-demos-UnemploymentRate             ZINC      citeseer   minesweeper  roman_empire\n",
       "0                sccn             NoReadOut  80.86 ± 2.16   70.64 ± 5.9  76.42 ± 0.88  75.49 ± 1.39  75.05 ± 2.76  88.04 ± 0.51              0.3588 ± 0.0246           0.8242 ± 0.0942           0.5751 ± 0.0553          0.5344 ± 0.0323              0.2868 ± 0.0276           0.9146 ± 0.1822                   0.4328 ± 0.044  0.5441 ± 0.0081   69.6 ± 1.83   88.85 ± 0.0   88.2 ± 0.22\n",
       "1                sccn   PropagateSignalDown  80.06 ± 1.66  73.62 ± 4.41  76.17 ± 1.39  75.31 ± 1.36  74.34 ± 3.17  88.37 ± 0.48               0.341 ± 0.0249           0.8264 ± 0.1018           0.5629 ± 0.0444          0.5686 ± 0.0247               0.2908 ± 0.032            0.9303 ± 0.172                  0.4734 ± 0.0377  0.4858 ± 0.0584   68.86 ± 2.4  89.07 ± 0.25  88.27 ± 0.14\n",
       "2        sccnn_custom             NoReadOut  82.19 ± 1.07  76.17 ± 6.63   76.6 ± 1.75  77.12 ± 1.07  74.19 ± 2.86  88.18 ± 0.32               0.3394 ± 0.028           0.7937 ± 0.1162           0.5527 ± 0.0474          0.5112 ± 0.0316              0.2825 ± 0.0279           0.8976 ± 0.1431                  0.4278 ± 0.0394   0.3562 ± 0.013  70.23 ± 2.69    87.4 ± 0.0  89.15 ± 0.32\n",
       "3        sccnn_custom   PropagateSignalDown  80.65 ± 2.39  70.64 ± 3.16   75.6 ± 2.45  75.43 ± 1.94  74.98 ± 1.92  87.78 ± 0.58              0.3449 ± 0.0314           0.8251 ± 0.1184            0.579 ± 0.0541            0.557 ± 0.041              0.3073 ± 0.0316           0.9274 ± 0.1711                  0.4538 ± 0.0428  0.4088 ± 0.0047  69.03 ± 2.01    89.0 ± 0.0  88.73 ± 0.12\n",
       "4                 scn             NoReadOut  82.27 ± 1.34  71.49 ± 2.43  75.27 ± 1.57    75.7 ± nan  75.27 ± 2.14   88.72 ± 0.5              0.3186 ± 0.0241           0.7122 ± 0.0836           0.5208 ± 0.0525           0.4648 ± 0.043              0.2526 ± 0.0247           0.9209 ± 0.1993                  0.3753 ± 0.0432        nan ± nan  71.24 ± 1.68  90.32 ± 0.11  85.89 ± 0.34\n",
       "5                 scn   PropagateSignalDown  79.91 ± 1.18  73.62 ± 6.13  74.46 ± 1.11   75.7 ± 1.04  74.77 ± 1.69  88.62 ± 0.44              0.3205 ± 0.0271           0.7985 ± 0.1062           0.5635 ± 0.0457          0.5091 ± 0.0345              0.2723 ± 0.0174           0.9619 ± 0.2329                  0.4131 ± 0.0297        nan ± nan   70.4 ± 1.53  90.27 ± 0.36  88.79 ± 0.46"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "today = date.today()\n",
    "api = wandb.Api()\n",
    "\n",
    "# # Find all csv files in the current directory\n",
    "csv_files = glob.glob(\"/home/lev/projects/TopoBenchmarkX/big_csv/*.csv\")\n",
    "# # Collect all the names of the csv files without the extension\n",
    "csv_names = [csv_file[:-4] for csv_file in csv_files]\n",
    "project_name = \"TopoBenchmarkX_Simplicial\"  \n",
    "user = \"telyatnikov_sap\"\n",
    "\n",
    "if project_name not in csv_names:\n",
    "    runs = api.runs(f\"{user}/{project_name}\")\n",
    "\n",
    "    summary_list, config_list, name_list = [], [], []\n",
    "    for run in runs:\n",
    "        # .summary contains the output keys/values for metrics like accuracy.\n",
    "        #  We call ._json_dict to omit large files\n",
    "        summary_list.append(run.summary._json_dict)\n",
    "\n",
    "        # .config contains the hyperparameters.\n",
    "        #  We remove special values that start with _.\n",
    "        config_list.append(\n",
    "            {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "        )\n",
    "\n",
    "        # .name is the human-readable name of the run.\n",
    "        name_list.append(run.name)\n",
    "\n",
    "    runs_df = pd.DataFrame(\n",
    "        {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\n",
    "    )\n",
    "\n",
    "    runs_df.to_csv(f\"{user}_{project_name}.csv\")\n",
    "else:\n",
    "    runs_df = pd.read_csv(f\"{project_name}.csv\", index_col=0)\n",
    "\n",
    "    for row in runs_df.iloc:\n",
    "        row[\"summary\"] = ast.literal_eval(row[\"summary\"])\n",
    "        row[\"config\"] = ast.literal_eval(row[\"config\"])\n",
    "\n",
    "\n",
    "for row in runs_df.iloc:\n",
    "    row[\"summary\"].update(row[\"config\"])\n",
    "\n",
    "lst = [i[\"summary\"] for i in runs_df.iloc]\n",
    "df = pd.DataFrame.from_dict(lst)\n",
    "\n",
    "df_init = df.copy()\n",
    "\n",
    "# Get average epoch run time\n",
    "df[\"epoch_run_time\"] = df[\"_runtime\"] / df[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, column_to_normalize):\n",
    "    # Use json_normalize to flatten the nested dictionaries into separate columns\n",
    "    flattened_df = pd.json_normalize(df[column_to_normalize])\n",
    "    # Rename columns to include 'nested_column' prefix\n",
    "    flattened_df.columns = [\n",
    "        f\"{column_to_normalize}.{col}\" for col in flattened_df.columns\n",
    "    ]\n",
    "    # Concatenate the flattened DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, flattened_df], axis=1)\n",
    "    # Get new columns names\n",
    "    new_columns = flattened_df.columns\n",
    "    # Drop the original nested column if needed\n",
    "    result_df.drop(column_to_normalize, axis=1, inplace=True)\n",
    "    return result_df, new_columns\n",
    "\n",
    "\n",
    "# Config columns to normalize\n",
    "columns_to_normalize = [\"model\", \"dataset\", \"callbacks\", \"paths\"]\n",
    "\n",
    "# Keep track of config columns added\n",
    "config_columns = []\n",
    "for column in columns_to_normalize:\n",
    "    df, columns = normalize_column(df, column)\n",
    "    config_columns.extend(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate tables to obtain full hp space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "additiona_runs = pd.read_csv('Simplicial_additional_runs.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr-Adam</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>val/recall</th>\n",
       "      <th>val/precision</th>\n",
       "      <th>train/accuracy</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>trainer/global_step</th>\n",
       "      <th>val/loss</th>\n",
       "      <th>train/recall</th>\n",
       "      <th>val/accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>callbacks.model_checkpoint.save_on_train_epoch_end</th>\n",
       "      <th>callbacks.rich_progress_bar._target_</th>\n",
       "      <th>callbacks.learning_rate_monitor._target_</th>\n",
       "      <th>callbacks.learning_rate_monitor.logging_interval</th>\n",
       "      <th>paths.log_dir</th>\n",
       "      <th>paths.data_dir</th>\n",
       "      <th>paths.root_dir</th>\n",
       "      <th>paths.work_dir</th>\n",
       "      <th>paths.output_dir</th>\n",
       "      <th>dataset.transforms.one_hot_node_degree_features.max_degrees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000990</td>\n",
       "      <td>1.716749e+09</td>\n",
       "      <td>0.643183</td>\n",
       "      <td>0.662108</td>\n",
       "      <td>0.637470</td>\n",
       "      <td>0.682051</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.669272</td>\n",
       "      <td>0.637904</td>\n",
       "      <td>0.641675</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000940</td>\n",
       "      <td>1.716749e+09</td>\n",
       "      <td>0.690025</td>\n",
       "      <td>0.724185</td>\n",
       "      <td>0.879800</td>\n",
       "      <td>0.263027</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.386238</td>\n",
       "      <td>0.757250</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX/logs/</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX/datasets/</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX/topobenchmarkx</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX/logs/train/m...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000882</td>\n",
       "      <td>1.716749e+09</td>\n",
       "      <td>0.743229</td>\n",
       "      <td>0.729881</td>\n",
       "      <td>0.939800</td>\n",
       "      <td>0.141516</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.571109</td>\n",
       "      <td>0.895250</td>\n",
       "      <td>0.825600</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX/logs/</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX/datasets/</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX/topobenchmarkx</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX/logs/train/m...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000841</td>\n",
       "      <td>1.716749e+09</td>\n",
       "      <td>0.720611</td>\n",
       "      <td>0.728938</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.163599</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.455577</td>\n",
       "      <td>0.873875</td>\n",
       "      <td>0.826400</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX/logs/</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX/datasets/</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX/topobenchmarkx</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX/logs/train/m...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000882</td>\n",
       "      <td>1.716749e+09</td>\n",
       "      <td>0.702433</td>\n",
       "      <td>0.716004</td>\n",
       "      <td>0.940400</td>\n",
       "      <td>0.146581</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.522819</td>\n",
       "      <td>0.910250</td>\n",
       "      <td>0.818800</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX/logs/</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX/datasets/</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX/topobenchmarkx</td>\n",
       "      <td>/home/lev/projects/TopoBenchmarkX/logs/train/m...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>0.007260</td>\n",
       "      <td>1.716589e+09</td>\n",
       "      <td>0.677322</td>\n",
       "      <td>0.713025</td>\n",
       "      <td>0.852600</td>\n",
       "      <td>0.302888</td>\n",
       "      <td>275.0</td>\n",
       "      <td>0.359202</td>\n",
       "      <td>0.706500</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/logs/</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/datasets/</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/hp_scripts/main_ex...</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/logs/train/multiru...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010</th>\n",
       "      <td>0.006960</td>\n",
       "      <td>1.716589e+09</td>\n",
       "      <td>0.682287</td>\n",
       "      <td>0.710489</td>\n",
       "      <td>0.854800</td>\n",
       "      <td>0.301027</td>\n",
       "      <td>305.0</td>\n",
       "      <td>0.363667</td>\n",
       "      <td>0.716125</td>\n",
       "      <td>0.816400</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/logs/</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/datasets/</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/hp_scripts/main_ex...</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/logs/train/multiru...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4011</th>\n",
       "      <td>0.006820</td>\n",
       "      <td>1.716589e+09</td>\n",
       "      <td>0.674839</td>\n",
       "      <td>0.714451</td>\n",
       "      <td>0.854400</td>\n",
       "      <td>0.301079</td>\n",
       "      <td>319.0</td>\n",
       "      <td>0.368256</td>\n",
       "      <td>0.721500</td>\n",
       "      <td>0.818800</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/logs/</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/datasets/</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/hp_scripts/main_ex...</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/logs/train/multiru...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>0.000676</td>\n",
       "      <td>1.716589e+09</td>\n",
       "      <td>0.738251</td>\n",
       "      <td>0.758098</td>\n",
       "      <td>0.908481</td>\n",
       "      <td>0.318860</td>\n",
       "      <td>325.0</td>\n",
       "      <td>0.606247</td>\n",
       "      <td>0.855169</td>\n",
       "      <td>0.813945</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/logs/</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/datasets/</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/hp_scripts/main_ex...</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/logs/train/multiru...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4013</th>\n",
       "      <td>0.000677</td>\n",
       "      <td>1.716589e+09</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.757856</td>\n",
       "      <td>0.910246</td>\n",
       "      <td>0.317179</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0.605372</td>\n",
       "      <td>0.860602</td>\n",
       "      <td>0.814122</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/logs/</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/datasets/</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/hp_scripts/main_ex...</td>\n",
       "      <td>/home/gbg141/TopoBenchmarkX/logs/train/multiru...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22175 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr-Adam    _timestamp  val/recall  val/precision  train/accuracy  \\\n",
       "0     0.000990  1.716749e+09    0.643183       0.662108        0.637470   \n",
       "1     0.000940  1.716749e+09    0.690025       0.724185        0.879800   \n",
       "2     0.000882  1.716749e+09    0.743229       0.729881        0.939800   \n",
       "3     0.000841  1.716749e+09    0.720611       0.728938        0.932000   \n",
       "4     0.000882  1.716749e+09    0.702433       0.716004        0.940400   \n",
       "...        ...           ...         ...            ...             ...   \n",
       "4009  0.007260  1.716589e+09    0.677322       0.713025        0.852600   \n",
       "4010  0.006960  1.716589e+09    0.682287       0.710489        0.854800   \n",
       "4011  0.006820  1.716589e+09    0.674839       0.714451        0.854400   \n",
       "4012  0.000676  1.716589e+09    0.738251       0.758098        0.908481   \n",
       "4013  0.000677  1.716589e+09    0.740146       0.757856        0.910246   \n",
       "\n",
       "      train/loss  trainer/global_step  val/loss  train/recall  val/accuracy  \\\n",
       "0       0.682051                 85.0  0.669272      0.637904      0.641675   \n",
       "1       0.263027                 60.0  0.386238      0.757250      0.824000   \n",
       "2       0.141516                119.0  0.571109      0.895250      0.825600   \n",
       "3       0.163599                160.0  0.455577      0.873875      0.826400   \n",
       "4       0.146581                119.0  0.522819      0.910250      0.818800   \n",
       "...          ...                  ...       ...           ...           ...   \n",
       "4009    0.302888                275.0  0.359202      0.706500      0.818000   \n",
       "4010    0.301027                305.0  0.363667      0.716125      0.816400   \n",
       "4011    0.301079                319.0  0.368256      0.721500      0.818800   \n",
       "4012    0.318860                325.0  0.606247      0.855169      0.813945   \n",
       "4013    0.317179                324.0  0.605372      0.860602      0.814122   \n",
       "\n",
       "      ...  callbacks.model_checkpoint.save_on_train_epoch_end  \\\n",
       "0     ...                                                NaN    \n",
       "1     ...                                                NaN    \n",
       "2     ...                                                NaN    \n",
       "3     ...                                                NaN    \n",
       "4     ...                                                NaN    \n",
       "...   ...                                                ...    \n",
       "4009  ...                                                NaN    \n",
       "4010  ...                                                NaN    \n",
       "4011  ...                                                NaN    \n",
       "4012  ...                                                NaN    \n",
       "4013  ...                                                NaN    \n",
       "\n",
       "             callbacks.rich_progress_bar._target_  \\\n",
       "0                                             NaN   \n",
       "1     lightning.pytorch.callbacks.RichProgressBar   \n",
       "2     lightning.pytorch.callbacks.RichProgressBar   \n",
       "3     lightning.pytorch.callbacks.RichProgressBar   \n",
       "4     lightning.pytorch.callbacks.RichProgressBar   \n",
       "...                                           ...   \n",
       "4009  lightning.pytorch.callbacks.RichProgressBar   \n",
       "4010  lightning.pytorch.callbacks.RichProgressBar   \n",
       "4011  lightning.pytorch.callbacks.RichProgressBar   \n",
       "4012  lightning.pytorch.callbacks.RichProgressBar   \n",
       "4013  lightning.pytorch.callbacks.RichProgressBar   \n",
       "\n",
       "             callbacks.learning_rate_monitor._target_  \\\n",
       "0                                                 NaN   \n",
       "1     lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "2     lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "3     lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "4     lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "...                                               ...   \n",
       "4009  lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "4010  lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "4011  lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "4012  lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "4013  lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "\n",
       "      callbacks.learning_rate_monitor.logging_interval  \\\n",
       "0                                                  NaN   \n",
       "1                                                epoch   \n",
       "2                                                epoch   \n",
       "3                                                epoch   \n",
       "4                                                epoch   \n",
       "...                                                ...   \n",
       "4009                                             epoch   \n",
       "4010                                             epoch   \n",
       "4011                                             epoch   \n",
       "4012                                             epoch   \n",
       "4013                                             epoch   \n",
       "\n",
       "                                paths.log_dir  \\\n",
       "0                                         NaN   \n",
       "1     /home/lev/projects/TopoBenchmarkX/logs/   \n",
       "2     /home/lev/projects/TopoBenchmarkX/logs/   \n",
       "3     /home/lev/projects/TopoBenchmarkX/logs/   \n",
       "4     /home/lev/projects/TopoBenchmarkX/logs/   \n",
       "...                                       ...   \n",
       "4009        /home/gbg141/TopoBenchmarkX/logs/   \n",
       "4010        /home/gbg141/TopoBenchmarkX/logs/   \n",
       "4011        /home/gbg141/TopoBenchmarkX/logs/   \n",
       "4012        /home/gbg141/TopoBenchmarkX/logs/   \n",
       "4013        /home/gbg141/TopoBenchmarkX/logs/   \n",
       "\n",
       "                                   paths.data_dir  \\\n",
       "0                                             NaN   \n",
       "1     /home/lev/projects/TopoBenchmarkX/datasets/   \n",
       "2     /home/lev/projects/TopoBenchmarkX/datasets/   \n",
       "3     /home/lev/projects/TopoBenchmarkX/datasets/   \n",
       "4     /home/lev/projects/TopoBenchmarkX/datasets/   \n",
       "...                                           ...   \n",
       "4009        /home/gbg141/TopoBenchmarkX/datasets/   \n",
       "4010        /home/gbg141/TopoBenchmarkX/datasets/   \n",
       "4011        /home/gbg141/TopoBenchmarkX/datasets/   \n",
       "4012        /home/gbg141/TopoBenchmarkX/datasets/   \n",
       "4013        /home/gbg141/TopoBenchmarkX/datasets/   \n",
       "\n",
       "                         paths.root_dir  \\\n",
       "0                                   NaN   \n",
       "1     /home/lev/projects/TopoBenchmarkX   \n",
       "2     /home/lev/projects/TopoBenchmarkX   \n",
       "3     /home/lev/projects/TopoBenchmarkX   \n",
       "4     /home/lev/projects/TopoBenchmarkX   \n",
       "...                                 ...   \n",
       "4009        /home/gbg141/TopoBenchmarkX   \n",
       "4010        /home/gbg141/TopoBenchmarkX   \n",
       "4011        /home/gbg141/TopoBenchmarkX   \n",
       "4012        /home/gbg141/TopoBenchmarkX   \n",
       "4013        /home/gbg141/TopoBenchmarkX   \n",
       "\n",
       "                                         paths.work_dir  \\\n",
       "0                                                   NaN   \n",
       "1      /home/lev/projects/TopoBenchmarkX/topobenchmarkx   \n",
       "2      /home/lev/projects/TopoBenchmarkX/topobenchmarkx   \n",
       "3      /home/lev/projects/TopoBenchmarkX/topobenchmarkx   \n",
       "4      /home/lev/projects/TopoBenchmarkX/topobenchmarkx   \n",
       "...                                                 ...   \n",
       "4009  /home/gbg141/TopoBenchmarkX/hp_scripts/main_ex...   \n",
       "4010  /home/gbg141/TopoBenchmarkX/hp_scripts/main_ex...   \n",
       "4011  /home/gbg141/TopoBenchmarkX/hp_scripts/main_ex...   \n",
       "4012  /home/gbg141/TopoBenchmarkX/hp_scripts/main_ex...   \n",
       "4013  /home/gbg141/TopoBenchmarkX/hp_scripts/main_ex...   \n",
       "\n",
       "                                       paths.output_dir  \\\n",
       "0                                                   NaN   \n",
       "1     /home/lev/projects/TopoBenchmarkX/logs/train/m...   \n",
       "2     /home/lev/projects/TopoBenchmarkX/logs/train/m...   \n",
       "3     /home/lev/projects/TopoBenchmarkX/logs/train/m...   \n",
       "4     /home/lev/projects/TopoBenchmarkX/logs/train/m...   \n",
       "...                                                 ...   \n",
       "4009  /home/gbg141/TopoBenchmarkX/logs/train/multiru...   \n",
       "4010  /home/gbg141/TopoBenchmarkX/logs/train/multiru...   \n",
       "4011  /home/gbg141/TopoBenchmarkX/logs/train/multiru...   \n",
       "4012  /home/gbg141/TopoBenchmarkX/logs/train/multiru...   \n",
       "4013  /home/gbg141/TopoBenchmarkX/logs/train/multiru...   \n",
       "\n",
       "     dataset.transforms.one_hot_node_degree_features.max_degrees  \n",
       "0                                                   NaN           \n",
       "1                                                   NaN           \n",
       "2                                                   NaN           \n",
       "3                                                   NaN           \n",
       "4                                                   NaN           \n",
       "...                                                 ...           \n",
       "4009                                                NaN           \n",
       "4010                                                NaN           \n",
       "4011                                                NaN           \n",
       "4012                                                NaN           \n",
       "4013                                                NaN           \n",
       "\n",
       "[22175 rows x 165 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df, additiona_runs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, additiona_runs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select models that have finished the runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workout us_demographic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every rows where df['dataset.parameters.data_name'] == 'US-county-demos' extend the 'dataset.parameters.data_name' with dataset.parameters.task_variable \n",
    "# and set it to 'US-county-demos' + '-' + dataset.parameters.task_variable\n",
    "df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.data_name'] = df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.data_name'] + '-' + df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.task_variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lr-Adam', '_timestamp', 'val/recall', 'val/precision', 'train/accuracy']\n",
      "['train/loss', 'trainer/global_step', 'val/loss', 'train/recall', 'val/accuracy']\n",
      "['train/precision', '_step', 'epoch', '_runtime', 'val/auroc']\n",
      "['train/auroc', 'seed', 'tags', 'extras', 'trainer']\n",
      "['ckpt_path', 'task_name', 'model/params/total', 'model/params/trainable', 'model/params/non_trainable']\n",
      "['test/auroc', 'test/accuracy', 'test/recall', 'test/precision', '_wandb']\n",
      "['test/loss', 'val/mae', 'val/mse', 'test/mae', 'train/mae']\n",
      "['test/mse', 'train/mse', 'epoch_run_time', 'model.compile', 'model._target_']\n",
      "['model.model_name', 'model.model_domain', 'model.loss.task', 'model.loss._target_', 'model.loss.loss_type']\n",
      "['model.readout._target_', 'model.readout.hidden_dim', 'model.readout.readout_name', 'model.readout.num_cell_dimensions', 'model.backbone._target_']\n",
      "['model.backbone.n_layers', 'model.backbone.sc_order', 'model.backbone.aggr_norm', 'model.backbone.conv_order', 'model.backbone.update_func']\n",
      "['model.backbone.in_channels_all', 'model.backbone.hidden_channels_all', 'model.optimizer.lr', 'model.optimizer._target_', 'model.optimizer._partial_']\n",
      "['model.optimizer.weight_decay', 'model.scheduler._target_', 'model.scheduler._partial_', 'model.scheduler.last_epoch', 'model.scheduler.total_iters']\n",
      "['model.head_model._target_', 'model.head_model.task_level', 'model.head_model.in_channels', 'model.head_model.out_channels', 'model.head_model.pooling_type']\n",
      "['model.head_model.head_model_name', 'model.feature_encoder._target_', 'model.feature_encoder.in_channels', 'model.feature_encoder.encoder_name', 'model.feature_encoder.out_channels']\n",
      "['model.feature_encoder.proj_dropout', 'model.feature_encoder.selected_dimensions', 'model.backbone_wrapper._target_', 'model.backbone_wrapper._partial_', 'model.backbone_wrapper.out_channels']\n",
      "['model.backbone_wrapper.wrapper_name', 'model.backbone_wrapper.num_cell_dimensions', 'model.backbone.in_channels_0', 'model.backbone.in_channels_1', 'model.backbone.in_channels_2']\n",
      "['model.backbone.channels', 'model.backbone.max_rank', 'dataset._target_', 'dataset.parameters.k', 'dataset.parameters.task']\n",
      "['dataset.parameters.data_dir', 'dataset.parameters.data_name', 'dataset.parameters.data_seed', 'dataset.parameters.data_type', 'dataset.parameters.loss_type']\n",
      "['dataset.parameters.batch_size', 'dataset.parameters.pin_memory', 'dataset.parameters.split_type', 'dataset.parameters.task_level', 'dataset.parameters.train_prop']\n",
      "['dataset.parameters.data_domain', 'dataset.parameters.num_classes', 'dataset.parameters.num_workers', 'dataset.parameters.force_reload', 'dataset.parameters.num_features']\n",
      "['dataset.parameters.data_split_dir', 'dataset.parameters.monitor_metric', 'dataset.transforms.graph2simplicial_lifting.signed', 'dataset.transforms.graph2simplicial_lifting._target_', 'dataset.transforms.graph2simplicial_lifting.complex_dim']\n",
      "['dataset.transforms.graph2simplicial_lifting.transform_name', 'dataset.transforms.graph2simplicial_lifting.transform_type', 'dataset.transforms.graph2simplicial_lifting.feature_lifting', 'dataset.transforms.graph2simplicial_lifting.preserve_edge_attr', 'dataset.parameters.max_node_degree']\n",
      "['dataset.transforms.data_manipulations._target_', 'dataset.transforms.data_manipulations.transform_name', 'dataset.transforms.data_manipulations.transform_type', 'dataset.transforms.data_manipulations.selected_fields', 'dataset.transforms.one_hot_node_degree_features._target_']\n",
      "['dataset.transforms.one_hot_node_degree_features.max_degree', 'dataset.transforms.one_hot_node_degree_features.degrees_fields', 'dataset.transforms.one_hot_node_degree_features.transform_name', 'dataset.transforms.one_hot_node_degree_features.transform_type', 'dataset.transforms.one_hot_node_degree_features.features_fields']\n",
      "['dataset.parameters.year', 'dataset.parameters.task_variable', 'dataset.parameters.max_dim_if_lifted', 'dataset.parameters.preserve_edge_attr_if_lifted', 'callbacks.model_summary._target_']\n",
      "['callbacks.model_summary.max_depth', 'callbacks.early_stopping.mode', 'callbacks.early_stopping.strict', 'callbacks.early_stopping.monitor', 'callbacks.early_stopping.verbose']\n",
      "['callbacks.early_stopping._target_', 'callbacks.early_stopping.patience', 'callbacks.early_stopping.min_delta', 'callbacks.early_stopping.check_finite', 'callbacks.early_stopping.stopping_threshold']\n",
      "['callbacks.early_stopping.divergence_threshold', 'callbacks.early_stopping.check_on_train_epoch_end', 'callbacks.model_checkpoint.mode', 'callbacks.model_checkpoint.dirpath', 'callbacks.model_checkpoint.monitor']\n",
      "['callbacks.model_checkpoint.verbose', 'callbacks.model_checkpoint._target_', 'callbacks.model_checkpoint.filename', 'callbacks.model_checkpoint.save_last', 'callbacks.model_checkpoint.save_top_k']\n",
      "['callbacks.model_checkpoint.every_n_epochs', 'callbacks.model_checkpoint.save_weights_only', 'callbacks.model_checkpoint.every_n_train_steps', 'callbacks.model_checkpoint.train_time_interval', 'callbacks.model_checkpoint.auto_insert_metric_name']\n",
      "['callbacks.model_checkpoint.save_on_train_epoch_end', 'callbacks.rich_progress_bar._target_', 'callbacks.learning_rate_monitor._target_', 'callbacks.learning_rate_monitor.logging_interval', 'paths.log_dir']\n",
      "['paths.data_dir', 'paths.root_dir', 'paths.work_dir', 'paths.output_dir', 'dataset.transforms.one_hot_node_degree_features.max_degrees']\n"
     ]
    }
   ],
   "source": [
    "# Print all columns 10 per line\n",
    "for i in range(0, len(df.columns), 5):\n",
    "    print(list(df.columns[i:i + 5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See unique datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'minesweeper' 'NCI1' 'roman_empire' 'ZINC' 'PROTEINS' 'NCI109'\n",
      " 'PubMed' 'citeseer' 'Cora' 'US-county-demos-UnemploymentRate'\n",
      " 'US-county-demos-BachelorRate' 'MUTAG' 'US-county-demos-DeathRate'\n",
      " 'US-county-demos-BirthRate' 'US-county-demos-MigraRate'\n",
      " 'US-county-demos-MedianIncome' 'US-county-demos-Election']\n",
      "Num unique datasets: 18\n"
     ]
    }
   ],
   "source": [
    "print(df['dataset.parameters.data_name'].unique())\n",
    "print(\"Num unique datasets:\", len(df['dataset.parameters.data_name'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See unique models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'sccnn_custom' 'scn' 'sccn']\n"
     ]
    }
   ],
   "source": [
    "print(df['model.model_name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve batch problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: sccnn_custom\n",
      "[1.]\n",
      "[1.]\n",
      "MODEL: scn\n",
      "[]\n",
      "[]\n",
      "MODEL: sccn\n",
      "[1.]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "datasets = ['minesweeper', 'roman_empire']\n",
    "models = ['sccnn_custom', 'scn', 'sccn']\n",
    "# For the following models and datasets I mistook the batch size, it should be 1, instead of 256 or 128\n",
    "# Keep the run where batch size is 128 and then change the batch size to 1\n",
    "for model in models:\n",
    "    print(\"MODEL:\", model)\n",
    "    for dataset in datasets:\n",
    "\n",
    "        # Change the batch size to 1 when it is 128\n",
    "        \n",
    "        print(df.loc[(df['model.model_name'] == model) & (df['dataset.parameters.data_name'] == dataset), 'dataset.parameters.batch_size'].unique())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve issue with projection dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ nan 0.25 0.5 ]\n"
     ]
    }
   ],
   "source": [
    "print(df['model.feature_encoder.proj_dropout'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep rows where model.feature_encoder.proj_dropout is [0.5  0.25]\n",
    "df = df[df['model.feature_encoder.proj_dropout'].isin([0.5, 0.25])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: sccnn_custom\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.25 0.5 ]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0. 9. 7. 5. 3.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI1\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[ 64.  32. 128.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.25 0.5 ]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[3. 9. 7. 0. 5.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 2.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0.]\n",
      "Column: seed\n",
      "[ 23.   5.  42.   3. 150.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI109\n",
      "Column: model.optimizer.lr\n",
      "[0.01]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[1. 4. 3. 2.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.25 0.5 ]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0. 9. 7. 5. 3.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64. 32.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n",
      "Model: scn\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI1\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI109\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64. 32.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n",
      "Model: sccn\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[5. 7. 0. 3. 9.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI1\n",
      "Column: model.optimizer.lr\n",
      "[0.01]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[1. 2. 4. 3.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128. 256.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[3. 0. 7. 9. 5.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[7. 0. 5. 9. 3.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 2.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128. 256.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0.]\n",
      "Column: seed\n",
      "[  5.   3. 150.  42.  23.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[7. 3. 0. 9. 5.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI109\n",
      "Column: model.optimizer.lr\n",
      "[0.01]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1. 4. 3.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.25 0.5 ]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128. 256.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[7. 9. 0. 3. 5.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64. 32.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 0. 5. 3.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n"
     ]
    }
   ],
   "source": [
    "# Sweeped parameters: \n",
    "sweeped_columns = [\n",
    "    'model.optimizer.lr', \n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.readout.readout_name',\n",
    "    'dataset.transforms.graph2simplicial_lifting.signed',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'dataset.parameters.batch_size',\n",
    "    'dataset.parameters.data_seed',\n",
    "    'seed',\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# For each model and dataset go over all the sweeped parameters and print the unique values\n",
    "for model in df['model.model_name'].unique():\n",
    "    print(f\"Model: {model}\")\n",
    "    for dataset in df['dataset.parameters.data_name'].unique():\n",
    "        print(f\"Dataset: {dataset}\")\n",
    "        for column in sweeped_columns:\n",
    "            print(f\"Column: {column}\")\n",
    "            print(df.loc[(df['model.model_name'] == model) & (df['dataset.parameters.data_name'] == dataset), column].unique())\n",
    "        \n",
    "        print('---------------NEW DATASET------------------')\n",
    "    print('---------------NEW MODEL------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best results for each model and dataset\n",
    "# 1. Keep the columns that are necessary for the comparison\n",
    "sweeped_columns = [\n",
    "    'model.optimizer.lr', \n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.readout.readout_name',\n",
    "    'dataset.transforms.graph2simplicial_lifting.signed',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'dataset.parameters.batch_size',\n",
    "    # 'dataset.parameters.data_seed',\n",
    "    # 'seed',\n",
    "]\n",
    "run_columns = ['dataset.parameters.data_seed','seed']\n",
    "\n",
    "# Dataset and model columns\n",
    "dataset_model_columns = ['model.model_name', 'dataset.parameters.data_name']\n",
    "\n",
    "# Performance columns\n",
    "performance_columns = [\n",
    "    'val/loss', 'test/loss',\n",
    "    'val/mae', 'test/mae',\n",
    "    'val/mse', 'test/mse',\n",
    "    'val/accuracy', 'test/accuracy',\n",
    "    'val/auroc','test/auroc',\n",
    "    'val/recall', 'test/recall',\n",
    "    'val/precision', 'test/precision',\n",
    "    ]\n",
    "keep_columns = dataset_model_columns + sweeped_columns + performance_columns + run_columns\n",
    "df = df[keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_classification = [\n",
    "    'val/accuracy', 'test/accuracy',\n",
    "    'val/auroc','test/auroc',\n",
    "    'val/recall', 'test/recall',\n",
    "    'val/precision', 'test/precision',\n",
    "    ]\n",
    "performance_regression = [\n",
    "    'val/mae', 'test/mae',\n",
    "    'val/mse', 'test/mse',\n",
    "    ]\n",
    "# Define a dict of dicts for each dataset the corresponding optimization metrics\n",
    "optimization_metrics = {\n",
    "    'IMDB-MULTI': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'IMDB-BINARY': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'REDDIT-BINARY': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'NCI109': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'NCI1': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'PROTEINS': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'MUTAG': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'Cora': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'citeseer': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'PubMed': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "\n",
    "    'roman_empire': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'amazon_ratings': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    \n",
    "    'tolokers': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'questions': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'minesweeper': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "\n",
    "    'ZINC': {'optim_metric': 'val/mse', 'eval_metric': 'test/mae', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    \n",
    "    'US-county-demos-UnemploymentRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-BachelorRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-DeathRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-BirthRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-MigraRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-MedianIncome': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-Election': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "\n",
    "} \n",
    "\n",
    "len(optimization_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique datasets\n",
    "datasets = list(df['dataset.parameters.data_name'].unique())\n",
    "# Get unique models\n",
    "models = list(df['model.model_name'].unique())\n",
    "\n",
    "best_results = defaultdict(dict)\n",
    "hp_runs = defaultdict(dict)\n",
    "best_runs = defaultdict(dict)\n",
    "# Got over each dataset and model and find the best result\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        # Get the subset of the DataFrame for the current dataset and model\n",
    "        subset = df[\n",
    "            (df['dataset.parameters.data_name'] == dataset)\n",
    "            & (df['model.model_name'] == model)\n",
    "        ]\n",
    "\n",
    "        optim_metric = optimization_metrics[dataset]['optim_metric']\n",
    "        eval_metric = optimization_metrics[dataset]['eval_metric']\n",
    "        direction = optimization_metrics[dataset]['direction']\n",
    "        \n",
    "        # Keep metrics that matters for dataset\n",
    "        performance_columns = optimization_metrics[dataset]['performance_columns']\n",
    "        subset = subset[dataset_model_columns + sweeped_columns + performance_columns + run_columns]\n",
    "\n",
    "        aggregated = subset.groupby(sweeped_columns, dropna=False).agg(\n",
    "            {col: [\"mean\", \"std\"] for col in performance_columns}\n",
    "        )\n",
    "\n",
    "         # Go from MultiIndex to Index\n",
    "        aggregated = aggregated.reset_index()\n",
    "        aggregated = aggregated.sort_values(\n",
    "                by=(optim_metric, \"mean\"), ascending=(direction == 'min')\n",
    "            )\n",
    "        \n",
    "        # Git percent in case of classification\n",
    "        if 'test/accuracy' in performance_columns:\n",
    "            # Go over all the performance columns and multiply by 100\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] *= 100\n",
    "                aggregated[(col, \"std\")] *= 100\n",
    "            \n",
    "            # Round performance columns values up to 2 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(2)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(2)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # Round all values up to 4 decimal points\n",
    "            # Round performance columns values up to 4 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(4)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(4)\n",
    "        \n",
    "            \n",
    "        \n",
    "        # Get the best result\n",
    "        final_best = aggregated.head(1)\n",
    "        if final_best[(eval_metric, \"mean\")].any(): \n",
    "            best_results[dataset][model] = {\n",
    "                \"mean\": final_best[(eval_metric, \"mean\")].values[0],\n",
    "                \"std\": final_best[(eval_metric, \"std\")].values[0],\n",
    "            }\n",
    "\n",
    "            # Extract best runs: \n",
    "            best_params = {}\n",
    "            for col in sweeped_columns:\n",
    "                best_params[col] = final_best[(col, '')].item()\n",
    "            \n",
    "            hp_runs[dataset][model] = subset.copy()\n",
    "            \n",
    "            # Start with the entire DataFrame\n",
    "            filtered_subset = subset.copy()\n",
    "\n",
    "            # Iterate over each key-value pair in the best parameters dictionary and filter the DataFrame\n",
    "            for param, value in best_params.items():\n",
    "                filtered_subset = filtered_subset[filtered_subset[param] == value]\n",
    "            best_runs[dataset][model] = filtered_subset\n",
    "        \n",
    "        else: \n",
    "            best_results[dataset][model] = {\n",
    "                \"mean\": np.nan,\n",
    "                \"std\": np.nan,\n",
    "            }\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "COLS = [\n",
    "    'dataset.parameters.data_seed',\n",
    "    'dataset.parameters.batch_size',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.readout.readout_name',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'model.optimizer.lr', \n",
    "    \n",
    "]\n",
    "\n",
    "a = hp_runs['US-county-demos-BirthRate']['scn'].sort_values(by=COLS, ascending=False)[COLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.parameters.data_seed\n",
      "5.0    92\n",
      "3.0    92\n",
      "7.0    90\n",
      "9.0    88\n",
      "0.0    88\n",
      "Name: count, dtype: int64\n",
      "dataset.parameters.batch_size\n",
      "1.0    450\n",
      "Name: count, dtype: int64\n",
      "model.backbone.n_layers\n",
      "3.0    117\n",
      "2.0    113\n",
      "4.0    111\n",
      "1.0    109\n",
      "Name: count, dtype: int64\n",
      "model.feature_encoder.out_channels\n",
      "128.0    153\n",
      "32.0     150\n",
      "64.0     147\n",
      "Name: count, dtype: int64\n",
      "model.readout.readout_name\n",
      "PropagateSignalDown    229\n",
      "NoReadOut              221\n",
      "Name: count, dtype: int64\n",
      "model.feature_encoder.proj_dropout\n",
      "0.25    232\n",
      "0.50    218\n",
      "Name: count, dtype: int64\n",
      "model.optimizer.lr\n",
      "0.001    229\n",
      "0.010    221\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in COLS:\n",
    "    print(a[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.parameters.data_seed\n",
      "5.0    92\n",
      "3.0    92\n",
      "7.0    90\n",
      "9.0    88\n",
      "0.0    88\n",
      "Name: count, dtype: int64\n",
      "dataset.parameters.batch_size\n",
      "1.0    450\n",
      "Name: count, dtype: int64\n",
      "model.backbone.n_layers\n",
      "3.0    117\n",
      "2.0    113\n",
      "4.0    111\n",
      "1.0    109\n",
      "Name: count, dtype: int64\n",
      "model.feature_encoder.out_channels\n",
      "128.0    153\n",
      "32.0     150\n",
      "64.0     147\n",
      "Name: count, dtype: int64\n",
      "model.readout.readout_name\n",
      "PropagateSignalDown    229\n",
      "NoReadOut              221\n",
      "Name: count, dtype: int64\n",
      "model.feature_encoder.proj_dropout\n",
      "0.25    232\n",
      "0.50    218\n",
      "Name: count, dtype: int64\n",
      "model.optimizer.lr\n",
      "0.001    229\n",
      "0.010    221\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in COLS:\n",
    "    print(a[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save obtained best results and best runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert nested dictionary to DataFrame\n",
    "nested_dict = dict(best_results)\n",
    "result_dict = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (i, j): nested_dict[i][j]\n",
    "        for i in nested_dict\n",
    "        for j in nested_dict[i].keys()\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "\n",
    "result_dict[\"performance\"] = result_dict.apply(\n",
    "    lambda x: f\"{x['mean']} ± {x['std']}\", axis=1\n",
    ")\n",
    "result_dict = result_dict.drop([\"mean\", \"std\"], axis=1)\n",
    "\n",
    "# Reset multiindex\n",
    "result_dict = result_dict.reset_index()\n",
    "# rename columns\n",
    "result_dict.columns = [\"Dataset\", \"Model\", \"Performance\"]\n",
    "\n",
    "result_dict = result_dict.pivot_table(\n",
    "    index=\"Model\", columns=\"Dataset\", values=\"Performance\", aggfunc=\"first\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Cora</th>\n",
       "      <th>MUTAG</th>\n",
       "      <th>NCI1</th>\n",
       "      <th>NCI109</th>\n",
       "      <th>PROTEINS</th>\n",
       "      <th>PubMed</th>\n",
       "      <th>US-county-demos-BachelorRate</th>\n",
       "      <th>US-county-demos-BirthRate</th>\n",
       "      <th>US-county-demos-DeathRate</th>\n",
       "      <th>US-county-demos-Election</th>\n",
       "      <th>US-county-demos-MedianIncome</th>\n",
       "      <th>US-county-demos-MigraRate</th>\n",
       "      <th>US-county-demos-UnemploymentRate</th>\n",
       "      <th>ZINC</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>minesweeper</th>\n",
       "      <th>roman_empire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sccn</th>\n",
       "      <td>80.86 ± 2.16</td>\n",
       "      <td>70.64 ± 5.9</td>\n",
       "      <td>75.27 ± 1.74</td>\n",
       "      <td>75.31 ± 1.36</td>\n",
       "      <td>75.05 ± 2.76</td>\n",
       "      <td>88.37 ± 0.48</td>\n",
       "      <td>0.3588 ± 0.0246</td>\n",
       "      <td>0.8242 ± 0.0942</td>\n",
       "      <td>0.5751 ± 0.0553</td>\n",
       "      <td>0.5344 ± 0.0323</td>\n",
       "      <td>0.2908 ± 0.032</td>\n",
       "      <td>0.9146 ± 0.1822</td>\n",
       "      <td>0.4328 ± 0.044</td>\n",
       "      <td>0.4858 ± 0.0584</td>\n",
       "      <td>69.6 ± 1.83</td>\n",
       "      <td>89.07 ± 0.25</td>\n",
       "      <td>88.27 ± 0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sccnn_custom</th>\n",
       "      <td>82.19 ± 1.07</td>\n",
       "      <td>76.17 ± 6.63</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>75.31 ± 0.47</td>\n",
       "      <td>74.19 ± 2.86</td>\n",
       "      <td>88.18 ± 0.32</td>\n",
       "      <td>0.3394 ± 0.028</td>\n",
       "      <td>0.7937 ± 0.1162</td>\n",
       "      <td>0.5527 ± 0.0474</td>\n",
       "      <td>0.5112 ± 0.0316</td>\n",
       "      <td>0.2825 ± 0.0279</td>\n",
       "      <td>0.8976 ± 0.1431</td>\n",
       "      <td>0.4278 ± 0.0394</td>\n",
       "      <td>0.4088 ± 0.0047</td>\n",
       "      <td>70.23 ± 2.69</td>\n",
       "      <td>89.0 ± 0.0</td>\n",
       "      <td>89.15 ± 0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scn</th>\n",
       "      <td>82.27 ± 1.34</td>\n",
       "      <td>73.62 ± 6.13</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>75.27 ± 2.14</td>\n",
       "      <td>88.72 ± 0.5</td>\n",
       "      <td>0.3186 ± 0.0241</td>\n",
       "      <td>0.7122 ± 0.0836</td>\n",
       "      <td>0.5208 ± 0.0525</td>\n",
       "      <td>0.4648 ± 0.043</td>\n",
       "      <td>0.2526 ± 0.0247</td>\n",
       "      <td>0.9209 ± 0.1993</td>\n",
       "      <td>0.3753 ± 0.0432</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>71.24 ± 1.68</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset               Cora         MUTAG          NCI1        NCI109      PROTEINS        PubMed US-county-demos-BachelorRate US-county-demos-BirthRate US-county-demos-DeathRate US-county-demos-Election US-county-demos-MedianIncome US-county-demos-MigraRate US-county-demos-UnemploymentRate             ZINC      citeseer   minesweeper  roman_empire\n",
       "Model                                                                                                                                                                                                                                                                                                                                                        \n",
       "sccn          80.86 ± 2.16   70.64 ± 5.9  75.27 ± 1.74  75.31 ± 1.36  75.05 ± 2.76  88.37 ± 0.48              0.3588 ± 0.0246           0.8242 ± 0.0942           0.5751 ± 0.0553          0.5344 ± 0.0323               0.2908 ± 0.032           0.9146 ± 0.1822                   0.4328 ± 0.044  0.4858 ± 0.0584   69.6 ± 1.83  89.07 ± 0.25  88.27 ± 0.14\n",
       "sccnn_custom  82.19 ± 1.07  76.17 ± 6.63     nan ± nan  75.31 ± 0.47  74.19 ± 2.86  88.18 ± 0.32               0.3394 ± 0.028           0.7937 ± 0.1162           0.5527 ± 0.0474          0.5112 ± 0.0316              0.2825 ± 0.0279           0.8976 ± 0.1431                  0.4278 ± 0.0394  0.4088 ± 0.0047  70.23 ± 2.69    89.0 ± 0.0  89.15 ± 0.32\n",
       "scn           82.27 ± 1.34  73.62 ± 6.13     nan ± nan     nan ± nan  75.27 ± 2.14   88.72 ± 0.5              0.3186 ± 0.0241           0.7122 ± 0.0836           0.5208 ± 0.0525           0.4648 ± 0.043              0.2526 ± 0.0247           0.9209 ± 0.1993                  0.3753 ± 0.0432        nan ± nan  71.24 ± 1.68     nan ± nan     nan ± nan"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the number of allowed rows to display\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "result_dict.to_csv(f\"best_results_simplicial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

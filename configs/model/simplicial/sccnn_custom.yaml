_target_: topobenchmarkx.models.TopologicalNetworkModule

model_name: sccnn_custom
model_domain: simplicial

feature_encoder:
  _target_: topobenchmarkx.models.encoders.${model.feature_encoder.encoder_name}
  encoder_name: AllCellFeatureEncoder
  in_channels: ${infer_in_channels:${dataset}} 
  out_channels: 128
  proj_dropout: 0.0
  selected_dimensions:
    - 0
    - 1
    - 2

backbone:
  _target_: custom_models.simplicial.sccnn.SCCNNCusctom
  in_channels_all:
    - ${model.feature_encoder.out_channels}
    - ${model.feature_encoder.out_channels}
    - ${model.feature_encoder.out_channels}
  hidden_channels_all:
    - ${model.backbone.in_channels_all[0]}
    - ${model.backbone.in_channels_all[1]}
    - ${model.backbone.in_channels_all[2]}
  conv_order: 1 # Increasing order make the training unstable 
  sc_order: 3
  aggr_norm: False
  update_func: "sigmoid"
  n_layers: 4

backbone_wrapper:
  _target_: topobenchmarkx.models.wrappers.SCCNNWrapper
  _partial_: true
  wrapper_name: SCCNNWrapper
  out_channels: ${model.feature_encoder.out_channels}
  num_cell_dimensions: ${infere_list_length:${model.feature_encoder.selected_dimensions}}

readout:
  _target_: topobenchmarkx.models.readouts.${model.readout.readout_name}
  readout_name: PropagateSignalDown #  Use <NoReadOut> in case readout is not needed Options: PropagateSignalDown
  hidden_dim: ${model.feature_encoder.out_channels}
  num_cell_dimensions: ${infere_list_length:${model.feature_encoder.selected_dimensions}}

head_model:
  _target_: topobenchmarkx.models.head_models.${model.head_model.head_model_name}
  head_model_name: ZeroCellModel
  in_channels: ${model.feature_encoder.out_channels}
  out_channels: ${dataset.parameters.num_classes}
  task_level: ${dataset.parameters.task_level}
  pooling_type: sum

loss:
  _target_: topobenchmarkx.models.losses.DefaultLoss
  task: ${dataset.parameters.task}
  loss_type: ${dataset.parameters.loss_type}

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.01 #0.01
  weight_decay: 0.0

scheduler:
  _target_: torch.optim.lr_scheduler.PolynomialLR
  _partial_: true
  last_epoch: -1
  total_iters: ${trainer.max_epochs}

# compile model for faster training with pytorch 2.0
compile: false
